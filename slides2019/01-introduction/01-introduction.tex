%=============================================================================%
% Author: 	John Joseph Valletta
% Date: 	02/04/2019
% Title: 	Fews slides for introduction to ML workshop
%=============================================================================%

% Preamble
 \documentclass[pdf]{beamer}
\usepackage[export]{adjustbox}
\usepackage{framed}
\usepackage{color}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{deepblue}{rgb}{0,0,0.5}
\definecolor{deepred}{rgb}{0.6,0,0}
\definecolor{deepgreen}{rgb}{0,0.5,0}
\definecolor{lightgray}{rgb}{0.92,0.92,0.92}
\definecolor{myblue}{rgb}{0.12, 0.47, 0.71} 
\definecolor{tealblue}{rgb}{0, 0.5, 0.5}
\usepackage{listings} % to insert code
\usepackage{textpos} % textblock
\usepackage{verbatim}
\usepackage{hyperref}
\hypersetup{colorlinks=true, urlcolor=blue, linkcolor=black} 

% Presentation configuration
\mode<presentation>{\usetheme{Madrid}}
\usecolortheme[named=myblue]{structure}
\useinnertheme{circles} % circles, rectanges, rounded, inmargin
\usefonttheme[onlymath]{serif} % makes math fonts like the usual LaTeX ones
\setbeamercovered{transparent=4} % transparent
\setbeamertemplate{caption}{\raggedright\insertcaption\par} % Remove the word "Figure" from caption %\setbeamertemplate{caption}[default]
\setbeamertemplate{navigation symbols}{} % don't put navigation tools at the bottom (alternatively \beamertemplatenavigationsymbolsempty)
\graphicspath{ {./img/} }

% Titlepage
\title[Introduction to Machine Learning]{Introduction to Machine Learning}
%\subtitle{Built-in data types}
\author{John Joseph Valletta}
\date[April 2019]{April 2019}
\institute[]{University of Exeter, Penryn Campus, UK}
\titlegraphic{
\hfill
\includegraphics[width=\textwidth, keepaspectratio]{logo.jpg}}

%=============================================================================%
%=============================================================================%
% Start of Document
%=============================================================================%
%=============================================================================%
\begin{document}

%=============================================================================%
%=============================================================================%
\begin{frame}
\titlepage
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Workshop learning outcomes}
\begin{itemize}\addtolength{\itemsep}{0.7\baselineskip}
	\item Understand the key concepts and terminology used in the field of machine learning
	\item Build predictive models for clustering and classification problems
	\item Apply machine learning algorithms in R to a variety of real-world datasets
	\item Recognise practical issues in data-driven modelling
\end{itemize}

\vfill
\textbf{Note}: All workshop material can be found here: 
\href{https://exeter-data-analytics.github.io/}{https://exeter-data-analytics.github.io/}

\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Recommended reading}
\begin{center}
	\includegraphics[width=0.25\textwidth, height=0.32\textwidth]{bookJames.png}
	\includegraphics[width=0.25\textwidth, height=0.32\textwidth]{bookHastie.png}\\
	\includegraphics[width=0.25\textwidth, height=0.32\textwidth]{bookBishop.png}
	\includegraphics[width=0.25\textwidth, height=0.32\textwidth]{bookMurphy.png}
\end{center}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Overview}
\begin{itemize}\addtolength{\itemsep}{0.5\baselineskip}
	\item Why are we here?
	\item What is machine learning?
	\item Types of machine learning methods
	\item Statistics vs Machine Learning
	\item Terminology
	\item A bird's-eye view of machine learning
\end{itemize}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Why are we here?}
The infamous \textbf{Big Data}!
\begin{center}	
	\includegraphics<1>[width=0.9\textwidth]{urbanLandCover.png}
	\includegraphics<2>[width=0.8\textwidth]{microArray.jpg}
\end{center}
%No. of observations $<<$ No. of predictors ($n << p$ problem)
\end{frame}

% Urban Land Cover

% Class: Land cover class (nominal) 
% BrdIndx: Border Index (shape variable) 
% Area: Area in m2 (size variable) 
% Round: Roundness (shape variable) 
% Bright: Brightness (spectral variable) 
% Compact: Compactness (shape variable) 
% ShpIndx: Shape Index (shape variable) 
% Mean_G: Green (spectral variable) 
% Mean_R: Red (spectral variable) 
% Mean_NIR: Near Infrared (spectral variable) 
% SD_G: Standard deviation of Green (texture variable) 
% SD_R: Standard deviation of Red (texture variable) 
% SD_NIR: Standard deviation of Near Infrared (texture variable) 
% LW: Length/Width (shape variable) 
% GLCM1: Gray-Level Co-occurrence Matrix [i forget which type of GLCM metric this one is] (texture variable) 
% Rect: Rectangularity (shape variable) 
% GLCM2: Another Gray-Level Co-occurrence Matrix attribute (texture variable) 
% Dens: Density (shape variable) 
% Assym: Assymetry (shape variable) 
% NDVI: Normalized Difference Vegetation Index (spectral variable) 
% BordLngth: Border Length (shape variable) 
% GLCM3: Another Gray-Level Co-occurrence Matrix attribute (texture variable) 

% Microarray

% Each spot contains many copies of the same DNA sequence
% that uniquely represents a gene from an organism. Spots are arranged in an orderly fashion into Pen-groups. 
% The organism is grown in two different conditions (a reference condition and a test condition). 
% RNA is extracted from the two cells, and is labelled with different dyes (red and
% green) during the synthesis of cDNA by reverse transcriptase

%=============================================================================%
%=============================================================================%
\begin{frame}{Water, water everywhere, nor any drop to drink}
\begin{center}	
	\includegraphics<1>[width=0.8\textwidth]{bigDataCartoon.jpg}
	\includegraphics<2>[width=0.8\textwidth]{pulpFiction.jpg}
\end{center}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{What's the problem?}
\begin{exampleblock}{Predicting fish species richness \vskip-1mm{\tiny Olden \textit{et al}. Q Rev Biol 2008, 83(2):171-193}}
\begin{description}
	\item[Data:] Lake surface area, shoreline perimeter, air temperature, precipitation and elevation
	% e.g mean = 5.3 --> average of 5.3 species for those particular conditions e.g area<=1.5km^2  
	\item[Method:] Decision trees (supervised)
\end{description}
\begin{center}
	\includegraphics[width=0.5\textwidth]{olden.pdf}
\end{center}
\end{exampleblock}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{What's the problem?}
\begin{exampleblock}{Detection of malarial parasites \vskip-1mm{\tiny Purwar \textit{et al}. Malar J 2011, 10:364}}
\begin{description}
	\item[Data:] Image intensity
	\item[Method:] Modified k-means clustering (unsupervised)
\end{description}
\begin{center}
	\includegraphics[width=0.54\textwidth]{purwar02.pdf}
	\includegraphics[width=0.46\textwidth]{purwar01.pdf}
\end{center}
\end{exampleblock}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{What's the problem?}
\begin{exampleblock}{Creating carbon-density maps \vskip-1mm{\tiny Baccini \textit{et al}. Nature Clim. Change 2012, 2:182-185}}
\begin{description}
	\item[Data:] Light detection and ranging (LiDAR) (elevation data)
	\item[Method:] Random forests (ensemble of decision trees) (supervised)
\end{description}
\begin{center}
	\includegraphics[width=0.65\textwidth]{baccini.pdf}
\end{center}
\end{exampleblock}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{What's the problem?}
\begin{exampleblock}{Acoustic classification of multiple simultaneous bird species \vskip-1mm{\tiny Briggs \textit{et al}. J Acoust Soc Am 2012, 131(6):4640-4650}}
\begin{description}
	\item[Data:] Segments in spectrogram (time vs frequency) from 10 secs audio recordings (corresponding to syllables of bird call)
	\item[Method:] Multi-instance multi-label learning (supervised)
\end{description}
\begin{center}
	\includegraphics[width=0.7\textwidth]{briggs.pdf}
\end{center}
\end{exampleblock}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{What my mum thinks machine learning is}
\begin{center}
	\includegraphics[width=\textwidth]{AI.jpg}
\end{center}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Who uses machine learning?}
\begin{columns}
\column{0.33\textwidth}
\begin{center}
	\includegraphics[width=\textwidth]{google.png}
	\vspace{2cm}
	\includegraphics[width=0.5\textwidth]{facebook.png}
\end{center}
\column{0.33\textwidth}
\begin{center}
	\includegraphics[width=\textwidth]{netflix.png}\\
	\includegraphics[width=\textwidth]{kinect.jpg}\\
	\includegraphics[width=\textwidth]{youtube.png}
\end{center}
\column{0.33\textwidth}
\begin{center}
	\includegraphics[width=0.5\textwidth]{AXA.png}\\
	\vspace{2cm}
	\includegraphics[width=\textwidth]{amazon.jpg}
\end{center}
\end{columns}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Who uses machine learning?}
\begin{columns}
\column{0.55\textwidth}
\begin{center}
	\includegraphics[width=\textwidth]{useML01.pdf}\\
	\vspace{2cm}
	\includegraphics[width=\textwidth]{useML02.pdf}
\end{center}
\column{0.45\textwidth}
\begin{center}
	\includegraphics[width=\textwidth]{useML03.pdf}\\
	\vspace{2cm}
	\includegraphics[width=\textwidth]{useML04.pdf}
\end{center}
\end{columns}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{There are even lucrative competitions!}
\begin{center}
	\includegraphics[width=.9\textwidth]{competition.png}
\end{center}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Lots of them actually...}
\begin{figure}
\begin{center}
	\includegraphics[width=0.65\textwidth]{competitions.png}
	\caption{\small{Source: http://www.kaggle.com/}}
\end{center}
\end{figure}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{So what is machine learning?}
\visible<2->{\begin{exampleblock}{}
{\small A machine learns with respect to a particular
task T, performance metric P, and type of experience E, if the system reliably improves its performance
P at task T, following experience E }
\vskip5mm
\hspace*\fill{\footnotesize --- Tom Mitchell}
\end{exampleblock}}
\vfill
\visible<3->{\begin{exampleblock}{}
{\small The scientific study of algorithms and statistical models that computer systems use to effectively 
perform a specific task without using explicit instructions, relying on patterns and inference instead}
\vskip5mm
\hspace*\fill{\footnotesize --- Wikipedia}
\end{exampleblock}}
\vfill
\visible<4->{
\begin{center}
	\textbf{Machines learn using flashcards}
\end{center}
}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Group by shape (unsupervised learning)}
\begin{center}
	\includegraphics[width=0.9\textwidth]{flashcardHidden.png}
\end{center}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Add labels (supervised learning)}
\begin{center}
	\includegraphics[width=0.9\textwidth]{flashcardExposed.png}
\end{center}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Types of machine learning methods: Unsupervised learning}
\vspace{0.5cm}
Inputs have \textit{no} corresponding output labels
\vspace{-0.5cm}
\begin{columns}
\column{0.65\textwidth}
\begin{itemize}\addtolength{\itemsep}{2\baselineskip}
	\item<2-> \underline{\textbf{Clustering}} - discovering groups having similar attributes% (e.g unlabelled gene expression profiles)
	\item<4-> \textbf{Density Estimation} - determine the distribution of data% (e.g species distribution model)
	\item<6-> \textbf{Dimensionality Reduction} - identify and remove redundant dimensions  
\end{itemize}
\column{0.35\textwidth}	
\begin{center}	
\visible<2->{\framezoom<2><3>(0.65\textwidth,0.85cm)(0.35\textwidth, 1cm) % (⟨upper left x⟩,⟨upper left y⟩) (⟨zoom area width⟩,⟨zoom area depth⟩)
			\includegraphics[width=0.75\textwidth,keepaspectratio]{clustering.pdf}}
\visible<4->{\framezoom<4><5>[border=4](0.65\textwidth, 3.595cm)(0.35\textwidth, 1cm)%\framezoom<4><5>(0.65\textwidth, 3.594cm)(0.2\textwidth, 2.8cm)
			\vspace{0.3cm}\includegraphics[width=0.75\textwidth,keepaspectratio]{densityEstimation.pdf}}
\visible<6->{\framezoom<6><7>(0.65\textwidth, 5.88cm)(0.35\textwidth, 1cm)
			 \includegraphics[width=0.73\textwidth,keepaspectratio]{PCA.pdf}}
\end{center}
\end{columns}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Types of machine learning methods: Supervised learning}
\vspace{0.5cm}
Inputs have corresponding output labels
\vspace{-0.5cm}
\begin{columns}
\column{0.58\textwidth}
\begin{itemize}\addtolength{\itemsep}{6\baselineskip}
	\item<2-> \textbf{Classification} - output is categorical
	\item<3-> \textbf{Regression} - output is continuous
\end{itemize}
\column{0.42\textwidth}	
\begin{center}
	\visible<2->{\includegraphics[width=1\textwidth, keepaspectratio]{classification.pdf}}
	\vfill
	\visible<3->{\includegraphics[width=1\textwidth, keepaspectratio]{regression.pdf}}
\end{center}
\end{columns}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Statistics vs Machine Learning (not mutually exclusive)}
\begin{center}
	\includegraphics[width=\textwidth]{breimanPaper.pdf}\\
	\includegraphics[width=0.75\textwidth]{statsvsML.png}
\end{center}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Statistics vs Machine Learning (not mutually exclusive)}
\footnotesize %\small, \footnotesize, \scriptsize, \tiny
\begin{columns}
\column{0.49\textwidth}
\begin{block}{Statistics}
	\begin{itemize}\addtolength{\itemsep}{0.6\baselineskip}
		\item<2-> \textbf{Philosophy} - provide humans a set of data analysis tools 
		\item<3-> \textbf{Focus} - what is the relationship between the data and the outcome? %a probabilistic data model and its interpretability
		\item<4-> \textbf{Inference} - how was the observed data generated
		\item<5-> \textbf{Learning} - All measured data then perform inference on the population
		\item<6-> \textbf{Validation} - Measures of fit ($R^2$, chi-square test)
		\item<7-> \textbf{Selection} - Adjusted measures of fit (adjusted $R^2$, Cp statistic, AIC)
	\end{itemize}
\end{block}
\column{0.49\textwidth}	
\begin{block}{Machine Learning}
	\begin{itemize}\addtolength{\itemsep}{0.6\baselineskip}
		\item<2-> \textbf{Philosophy} - replace humans in the processing of data  
		\item<3-> \textbf{Focus} - how can we predict the outcome using the data? % algorithm that achieves excellent prediction accuracy
		\item<4-> \textbf{Prediction} - how can we use observed data to predict the future
		\item<5-> \textbf{Learning} - Training dataset then perform predictions on testing dataset
		\item<6-> \textbf{Validation} - How well it predicts ``unseen'' data (generalisation)
		\item<7-> \textbf{Selection} - Cross-validation and out-of-bag errors
	\end{itemize}
\end{block}
\end{columns}
\end{frame}
\normalsize

%=============================================================================%
%=============================================================================%
\begin{frame}{Statistics and machine learning complement each other}
% \begin{exampleblock}{}
% {\small This enterprise (statistics) has at its heart the belief that a statistician, by imagination and by looking at the data, can invent a reasonably good parametric class of models for a complex mechanism devised by nature. Then parameters are estimated and conclusions are drawn. The conclusions are about the model's mechanism, and not about nature's mechanism!}
% \vskip5mm
% \hspace*\fill{\footnotesize --- Leo Breiman}
% \end{exampleblock}
% \vfill
\begin{exampleblock}{}
{\small The best solution could be an algorithmic model (machine learning), or maybe a data model, or maybe a combination. But the trick to being a \textbf{scientist} is to be open to using a wide variety of tools.}
\vskip5mm
\hspace*\fill{\footnotesize --- Leo Breiman}
\end{exampleblock}
\vfill
% \begin{exampleblock}{}
% {\small \textbf{Machine learning} extends a scientist's toolbox to deal with the explosion of data that the life sciences have seen in recent years due to the changing nature of science and technology}
% \end{exampleblock}
\vfill
\begin{exampleblock}{}
The objective is not just to get a better fit to the data but to have a predictive model that \textit{generalises} well, that is, gives good predictions to \textit{unseen} data 
\end{exampleblock}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{Terminology}
\begin{description}[Validation Dataset:]\addtolength{\itemsep}{0.5\baselineskip}
	\item<2->[Training Dataset:] Used to train a set of models
	\item<3->[Validation Dataset:] Used for model selection and validation. Helps us to select a 
	parsimonous model i.e a model which is complex enough to describe ``well'' our data but not more 
	complex
	\item<4->[Testing Dataset:] Used to compute the \textit{generalisation} error. Evaluate model
	performance on previously unseen data 
	\item<5->[Features:] Covariates, Predictors, Inputs, Attributes
	\item<6->[Training error:] In sample error, Resubstitution error
	\item<7->[Testing error:] Out of sample error, Generlisation error
\end{description}
\end{frame}

%=============================================================================%
%=============================================================================%
\begin{frame}{A bird's-eye view of machine learning}
\begin{center}
	\includegraphics[width=0.58\textwidth]{birdview.png}
\end{center}
\end{frame}
% \begin{enumerate}\addtolength{\itemsep}{0.5\baselineskip}
% 	\item<2-> Question/Hypothesis (start generic then narrow it down)
% 	\item<3-> Gather useful data
% 	\item<4-> \textbf{Extract features} (\textit{most important step})
% 	\item<5-> Choose a machine learning algorithm (\textit{probably least critical step})
% 	\item<6-> Build a predictive model
% 	\item<7-> Validate model
% 	\item<8-> Select model having the best generalisation capabilities
% \end{enumerate}

%=============================================================================%
%=============================================================================%
\end{document}
%-------------------------------------------------------------------------------------------------%
% End of Document
%-------------------------------------------------------------------------------------------------%
<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 Clustering | Introduction to Machine Learning</title>
  <meta name="description" content="2 Clustering | Introduction to Machine Learning" />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="2 Clustering | Introduction to Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="2 Clustering | Introduction to Machine Learning" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Clustering | Introduction to Machine Learning" />
  
  <meta name="twitter:description" content="2 Clustering | Introduction to Machine Learning" />
  

<meta name="author" content="Chris Yeomans and Jiangjiao Xu" />


<meta name="date" content="2020-03-26" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="dimensionality-reduction.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script language="javascript"> 
    function toggle(id) {
        var ele = document.getElementById("toggleText" + id);
        var text = document.getElementById("displayText" + id);
        var buttonText = text.innerHTML.replace("Show ", "");
        buttonText = buttonText.replace("Hide ", "");
        if(ele.style.display == "block") {
            ele.style.display = "none";
            text.innerHTML = "Show " + buttonText;
        } else {
            ele.style.display = "block";
            text.innerHTML = "Hide " + buttonText;
        }
    } 
</script>

<script language="javascript">
    function openCode(evt, codeName, id) {
        var i, tabcontent, tablinks;
        tabcontent = document.getElementsByClassName("tabcontent" + id);
        for (i = 0; i < tabcontent.length; i++) {
            tabcontent[i].style.display = "none";
        }
        tablinks = document.getElementsByClassName("tablinks" + id);
        for (i = 0; i < tablinks.length; i++) {
            tablinks[i].className = tablinks[i].className.replace(" active", "");
        }
        document.getElementById(codeName).style.display = "block";
        evt.currentTarget.className += " active";
    }
</script>

<script language="javascript">
    function hide(id){
        document.getElementById(id).style.display = "none";
    }
</script>
</script>

<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="_style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#learning-outcomes"><i class="fa fa-check"></i>Learning outcomes</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#recommended-reading"><i class="fa fa-check"></i>Recommended reading</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#software-packages"><i class="fa fa-check"></i>Software packages</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#data-files"><i class="fa fa-check"></i>Data files</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="introduction.html"><a href="introduction.html#motivation"><i class="fa fa-check"></i><b>1.1</b> Motivation</a></li>
<li class="chapter" data-level="1.2" data-path="introduction.html"><a href="introduction.html#what-is-machine-learning"><i class="fa fa-check"></i><b>1.2</b> What is machine learning?</a></li>
<li class="chapter" data-level="1.3" data-path="introduction.html"><a href="introduction.html#what-problems-can-machine-learning-solve"><i class="fa fa-check"></i><b>1.3</b> What problems can machine learning solve?</a></li>
<li class="chapter" data-level="1.4" data-path="introduction.html"><a href="introduction.html#types-of-machine-learning-methods"><i class="fa fa-check"></i><b>1.4</b> Types of machine learning methods</a><ul>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#unsupervised-learning"><i class="fa fa-check"></i>Unsupervised learning</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#supervised-learning"><i class="fa fa-check"></i>Supervised learning</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#semi-supervised-learning"><i class="fa fa-check"></i>Semi-supervised learning</a></li>
<li class="chapter" data-level="" data-path="introduction.html"><a href="introduction.html#reinforcement-learning"><i class="fa fa-check"></i>Reinforcement learning</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction.html"><a href="introduction.html#statistics-and-machine-learning"><i class="fa fa-check"></i><b>1.5</b> Statistics and Machine Learning</a></li>
<li class="chapter" data-level="1.6" data-path="introduction.html"><a href="introduction.html#terminology"><i class="fa fa-check"></i><b>1.6</b> Terminology</a></li>
<li class="chapter" data-level="1.7" data-path="introduction.html"><a href="introduction.html#a-birds-eye-view-of-building-machine-learning-systems"><i class="fa fa-check"></i><b>1.7</b> A bird’s-eye view of building machine learning systems</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>2</b> Clustering</a><ul>
<li class="chapter" data-level="2.1" data-path="clustering.html"><a href="clustering.html#motivation-1"><i class="fa fa-check"></i><b>2.1</b> Motivation</a></li>
<li class="chapter" data-level="2.2" data-path="clustering.html"><a href="clustering.html#what-is-clustering"><i class="fa fa-check"></i><b>2.2</b> What is clustering?</a></li>
<li class="chapter" data-level="2.3" data-path="clustering.html"><a href="clustering.html#what-problems-can-clustering-solve"><i class="fa fa-check"></i><b>2.3</b> What problems can clustering solve?</a></li>
<li class="chapter" data-level="2.4" data-path="clustering.html"><a href="clustering.html#types-of-clustering-methods"><i class="fa fa-check"></i><b>2.4</b> Types of clustering methods</a></li>
<li class="chapter" data-level="2.5" data-path="clustering.html"><a href="clustering.html#sec:similarity"><i class="fa fa-check"></i><b>2.5</b> Similarity measures</a></li>
<li class="chapter" data-level="2.6" data-path="clustering.html"><a href="clustering.html#the-iris-dataset"><i class="fa fa-check"></i><b>2.6</b> The <em>Iris</em> dataset</a></li>
<li class="chapter" data-level="2.7" data-path="clustering.html"><a href="clustering.html#k-means"><i class="fa fa-check"></i><b>2.7</b> <span class="math inline">\(k\)</span>-means</a></li>
<li class="chapter" data-level="2.8" data-path="clustering.html"><a href="clustering.html#agglomerative-hiearchical-clustering"><i class="fa fa-check"></i><b>2.8</b> Agglomerative hiearchical clustering</a></li>
<li class="chapter" data-level="2.9" data-path="clustering.html"><a href="clustering.html#gaussian-mixture-model-gmm"><i class="fa fa-check"></i><b>2.9</b> Gaussian mixture model (GMM)</a></li>
<li class="chapter" data-level="2.10" data-path="clustering.html"><a href="clustering.html#determining-the-correct-number-of-clusters"><i class="fa fa-check"></i><b>2.10</b> Determining the “correct” number of clusters</a></li>
<li class="chapter" data-level="2.11" data-path="clustering.html"><a href="clustering.html#tasks"><i class="fa fa-check"></i><b>2.11</b> Tasks</a><ul>
<li class="chapter" data-level="2.11.1" data-path="clustering.html"><a href="clustering.html#simulated-data"><i class="fa fa-check"></i><b>2.11.1</b> Simulated data</a></li>
<li class="chapter" data-level="2.11.2" data-path="clustering.html"><a href="clustering.html#gene-expression"><i class="fa fa-check"></i><b>2.11.2</b> Gene expression</a></li>
<li class="chapter" data-level="2.11.3" data-path="clustering.html"><a href="clustering.html#wine"><i class="fa fa-check"></i><b>2.11.3</b> Wine</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html"><i class="fa fa-check"></i><b>3</b> Dimensionality Reduction</a><ul>
<li class="chapter" data-level="3.1" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#feature-extraction"><i class="fa fa-check"></i><b>3.1</b> Feature extraction</a><ul>
<li class="chapter" data-level="3.1.1" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#pca"><i class="fa fa-check"></i><b>3.1.1</b> PCA</a></li>
<li class="chapter" data-level="3.1.2" data-path="dimensionality-reduction.html"><a href="dimensionality-reduction.html#t-sne"><i class="fa fa-check"></i><b>3.1.2</b> t-SNE</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html"><i class="fa fa-check"></i><b>4</b> Supervised Learning</a><ul>
<li class="chapter" data-level="4.1" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html#motivation-2"><i class="fa fa-check"></i><b>4.1</b> Motivation</a></li>
<li class="chapter" data-level="4.2" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html#what-is-supervised-learning"><i class="fa fa-check"></i><b>4.2</b> What is supervised learning?</a></li>
<li class="chapter" data-level="4.3" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html#what-problems-can-supervised-learning-solve"><i class="fa fa-check"></i><b>4.3</b> What problems can supervised learning solve?</a></li>
<li class="chapter" data-level="4.4" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html#cross-validation"><i class="fa fa-check"></i><b>4.4</b> Cross-validation</a></li>
<li class="chapter" data-level="4.5" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html#predictive-performance-measures"><i class="fa fa-check"></i><b>4.5</b> Predictive performance measures</a></li>
<li class="chapter" data-level="4.6" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html#k-nearest-neighbour-knn"><i class="fa fa-check"></i><b>4.6</b> <span class="math inline">\(k\)</span>-nearest neighbour (<span class="math inline">\(k\)</span>NN)</a></li>
<li class="chapter" data-level="4.7" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html#decision-trees"><i class="fa fa-check"></i><b>4.7</b> Decision trees</a></li>
<li class="chapter" data-level="4.8" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html#random-forests"><i class="fa fa-check"></i><b>4.8</b> Random forests</a></li>
<li class="chapter" data-level="4.9" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html#support-vector-machines-svm"><i class="fa fa-check"></i><b>4.9</b> Support vector machines (SVM)</a></li>
<li class="chapter" data-level="4.10" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html#tasks-1"><i class="fa fa-check"></i><b>4.10</b> Tasks</a><ul>
<li class="chapter" data-level="4.10.1" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html#gene-expression-1"><i class="fa fa-check"></i><b>4.10.1</b> Gene expression</a></li>
<li class="chapter" data-level="4.10.2" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html#wine-1"><i class="fa fa-check"></i><b>4.10.2</b> Wine</a></li>
<li class="chapter" data-level="4.10.3" data-path="supervised-learning-1.html"><a href="supervised-learning-1.html#uci-machine-learning-repository"><i class="fa fa-check"></i><b>4.10.3</b> UCI Machine Learning Repository</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Introduction to Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="clustering" class="section level1">
<h1><span class="header-section-number">2</span> Clustering</h1>
<div id="motivation-1" class="section level2">
<h2><span class="header-section-number">2.1</span> Motivation</h2>
<p><img src="_img/02-microarray.jpg" width="700px" style="display: block; margin: auto;" /></p>
<p>The image above is from a microarray experiment <a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>. The intensity
of each dot represents gene expression of a single gene (how “active” the gene is) for a particular individual/sample.
The resultant data is therefore a big matrix of numbers, where each column represents a gene and
each row an individual/sample.</p>
<p>There are two questions of interest:</p>
<ol style="list-style-type: decimal">
<li>Which genes are co-regulated, that is, behave in the same way?</li>
<li>Which individuals are similar to each other, that is, have a similar gene expression profile?</li>
</ol>
<p>In both cases we want to discover some underlying structure in <em>unlabelled</em> data. Structure means patterns
in the data that are sufficiently different from pure unstructured noise. Here we introduce clustering,
a class of unsupervised learning methods that try to answer these questions.</p>
</div>
<div id="what-is-clustering" class="section level2">
<h2><span class="header-section-number">2.2</span> What is clustering?</h2>
<blockquote>
<p>The goal of clustering is to find groups that share similar properties.
The data in each group should be similar (minimise intracluster distance), but each
cluster should be sufficiently different (maximise intercluster similarity).</p>
</blockquote>
<p><img src="_img/02-clustering.png" width="600px" style="display: block; margin: auto;" /></p>
</div>
<div id="what-problems-can-clustering-solve" class="section level2">
<h2><span class="header-section-number">2.3</span> What problems can clustering solve?</h2>
<p>Clustering is particularly useful in applications where labelling the data is very time consuming/expensive.</p>
<ul>
<li><p><strong>Gene expression</strong>: discovering co-regulated genes.</p></li>
<li><p><strong>Biological systematics</strong>: finding organisms sharing similar attributes.</p></li>
<li><p><strong>Computer vision</strong>: segmenting a digital image for object recognition.</p></li>
<li><p><strong>Epidemiology</strong>: identifying geographical clusters of diseases.</p></li>
<li><p><strong>Medical imaging</strong>: differentiating between tissues.</p></li>
<li><p><strong>Mathematical chemistry</strong>: grouping compounds by topological indices.</p></li>
<li><p><strong>Market basket analysis</strong>: determining which group of items tend to be bought together.</p></li>
<li><p><strong>Cybersecurity</strong>: detecting fraudulent activity.</p></li>
<li><p>… and much more!</p></li>
</ul>
</div>
<div id="types-of-clustering-methods" class="section level2">
<h2><span class="header-section-number">2.4</span> Types of clustering methods</h2>
<ul>
<li><p><strong>Partitional</strong>: the feature space is partitioned into <span class="math inline">\(k\)</span> regions e.g <span class="math inline">\(k\)</span>-means.</p></li>
<li><p><strong>Hierarchical</strong>: iteratively merging small clusters into larger ones (<em>agglomerative</em>) or breaking
large clusters into smaller ones (<em>divisive</em>).</p></li>
<li><p><strong>Distribution-based</strong>: fit <span class="math inline">\(k\)</span> multivariate statistical distributions e.g Gaussian mixture model (GMM).</p></li>
</ul>
</div>
<div id="sec:similarity" class="section level2">
<h2><span class="header-section-number">2.5</span> Similarity measures</h2>
<p>Most clustering methods rely on distance metrics that quantify how close two observations are. There
are several ways to define this distance, which has a direct effect on the clustering result.</p>
<p>The Euclidean distance (think Pythagoras theorem) is depicted below, together with the Manhatttan distance
(named after the journey a taxi has to follow in grid-like streets of cities like Manhattan).</p>
<p><img src="_img/02-euclidean.png" width="400px" style="display: block; margin: auto;" /></p>
<p>The correlation coefficient is also another popular way to measure similarity.</p>
<p><img src="_img/02-correlation.png" width="500px" style="display: block; margin: auto;" /></p>
<p>There are various other distance metrics, please see <a href="https://www.rdocumentation.org/packages/stats/versions/3.5.3/topics/dist"><code>dist</code></a> in R or <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.distance.pdist.html"><code>pdist</code></a> in Python.
In this introductory workshop we will focus on continuous features, but be aware that distance measures
for categorical variables exists, such as, the <a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard index</a>,
<a href="https://cran.r-project.org/web/packages/gower/index.html">Gower distance</a> and <a href="https://en.wikipedia.org/wiki/Polychoric_correlation">polychoric correlation</a>.</p>
</div>
<div id="the-iris-dataset" class="section level2">
<h2><span class="header-section-number">2.6</span> The <em>Iris</em> dataset</h2>
<p>To showcase some of the clustering methods, we will use the popular <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set"><em>Iris</em> dataset</a>. The data set
consists of 50 samples from three species of <em>Iris</em> flower (<em>I. setosa</em>, <em>I. virginica</em> and <em>I. versicolor</em>).
Each flower is quantified by four measurements, length and width of sepal and petal.</p>
<p>Let us load this dataset:</p>
<div class="tab">
<button class="tablinksunnamed-chunk-14 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-14', 'unnamed-chunk-14');">
R
</button>
<button class="tablinksunnamed-chunk-14" onclick="javascript:openCode(event, 'option2unnamed-chunk-14', 'unnamed-chunk-14');">
Python
</button>
</div>
<div id="option1unnamed-chunk-14" class="tabcontentunnamed-chunk-14">
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="co"># The iris dataset is preloaded in R</span></a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="kw">head</span>(iris)</a></code></pre></div>
<pre><code>  Sepal.Length Sepal.Width Petal.Length Petal.Width Species
1          5.1         3.5          1.4         0.2  setosa
2          4.9         3.0          1.4         0.2  setosa
3          4.7         3.2          1.3         0.2  setosa
4          4.6         3.1          1.5         0.2  setosa
5          5.0         3.6          1.4         0.2  setosa
6          5.4         3.9          1.7         0.4  setosa</code></pre>
</div>
<div id="option2unnamed-chunk-14" class="tabcontentunnamed-chunk-14">
<div class="sourceCode" id="cb3"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="co"># The iris dataset is available from the sci-kit learn package</span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2"><span class="im">from</span> sklearn <span class="im">import</span> datasets</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">iris <span class="op">=</span> datasets.load_iris()</a>
<a class="sourceLine" id="cb3-4" data-line-number="4"></a>
<a class="sourceLine" id="cb3-5" data-line-number="5"><span class="co"># Print the first 6 rows</span></a>
<a class="sourceLine" id="cb3-6" data-line-number="6"><span class="co"># Sepal Length, Sepal Width, Petal Length, Petal Width</span></a>
<a class="sourceLine" id="cb3-7" data-line-number="7">iris.data[:<span class="dv">6</span>, ]</a></code></pre></div>
<pre><code>array([[5.1, 3.5, 1.4, 0.2],
       [4.9, 3. , 1.4, 0.2],
       [4.7, 3.2, 1.3, 0.2],
       [4.6, 3.1, 1.5, 0.2],
       [5. , 3.6, 1.4, 0.2],
       [5.4, 3.9, 1.7, 0.4]])</code></pre>
</div>
<script> javascript:hide('option2unnamed-chunk-14') </script>
</div>
<div id="k-means" class="section level2">
<h2><span class="header-section-number">2.7</span> <span class="math inline">\(k\)</span>-means</h2>
<p>Arguably the most widely used partitioning clustering method.
The feature space is divided into <span class="math inline">\(k\)</span> regions as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Select <span class="math inline">\(k\)</span> centroids at random.</p></li>
<li><p>Compute the Euclidean distance between centroids and each data point.</p></li>
<li><p>Assign each data point to the closest centroid.</p></li>
<li><p>Compute new centroids; the average of all data points in that cluster.</p></li>
<li><p>Repeat steps 2 to 4 until data points remain in the same cluster or some maximum number of iterations reached.</p></li>
</ol>
<p><strong>Note</strong>: <span class="math inline">\(k\)</span>-means clustering should <strong>only</strong> be used with continuous data!</p>
<p>For visualisation purposes let’s just use two features of the <em>Iris</em> dataset; sepal length and petal width.</p>
<div class="tab">
<button class="tablinksunnamed-chunk-15 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-15', 'unnamed-chunk-15');">
R
</button>
<button class="tablinksunnamed-chunk-15" onclick="javascript:openCode(event, 'option2unnamed-chunk-15', 'unnamed-chunk-15');">
Python
</button>
</div>
<div id="option1unnamed-chunk-15" class="tabcontentunnamed-chunk-15">
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="co"># Fit k-means model</span></a>
<a class="sourceLine" id="cb5-2" data-line-number="2">k &lt;-<span class="st"> </span><span class="dv">3</span></a>
<a class="sourceLine" id="cb5-3" data-line-number="3">mdl &lt;-<span class="st"> </span><span class="kw">kmeans</span>(<span class="dt">x=</span>iris[, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">4</span>)], <span class="dt">centers=</span>k)</a>
<a class="sourceLine" id="cb5-4" data-line-number="4"></a>
<a class="sourceLine" id="cb5-5" data-line-number="5"><span class="co"># Associate a colour with each cluster</span></a>
<a class="sourceLine" id="cb5-6" data-line-number="6"><span class="kw">library</span>(RColorBrewer)</a>
<a class="sourceLine" id="cb5-7" data-line-number="7">COL &lt;-<span class="st"> </span><span class="kw">seq</span>(k)</a>
<a class="sourceLine" id="cb5-8" data-line-number="8"><span class="kw">names</span>(COL) &lt;-<span class="st"> </span><span class="kw">brewer.pal</span>(<span class="dt">n=</span>k, <span class="st">&#39;Set1&#39;</span>)</a>
<a class="sourceLine" id="cb5-9" data-line-number="9"></a>
<a class="sourceLine" id="cb5-10" data-line-number="10"><span class="co"># Plot results</span></a>
<a class="sourceLine" id="cb5-11" data-line-number="11"><span class="kw">plot</span>(iris[, <span class="dv">4</span>], iris[, <span class="dv">1</span>], <span class="dt">pch=</span><span class="dv">19</span>, <span class="dt">col=</span><span class="kw">names</span>(COL[mdl<span class="op">$</span>cluster]),</a>
<a class="sourceLine" id="cb5-12" data-line-number="12">     <span class="dt">xlab=</span><span class="st">&#39;Petal width (cm)&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Sepal length (cm)&#39;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-68-1.png" style="display: block; margin: auto;" /></p>
</div>
<div id="option2unnamed-chunk-15" class="tabcontentunnamed-chunk-15">
<div class="sourceCode" id="cb6"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb6-1" data-line-number="1"><span class="co"># Fit k-means model</span></a>
<a class="sourceLine" id="cb6-2" data-line-number="2"><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</a>
<a class="sourceLine" id="cb6-3" data-line-number="3">k <span class="op">=</span> <span class="dv">3</span></a>
<a class="sourceLine" id="cb6-4" data-line-number="4">mdl <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k, n_jobs<span class="op">=-</span><span class="dv">1</span>) <span class="co"># -1 uses all cores</span></a>
<a class="sourceLine" id="cb6-5" data-line-number="5">mdl.fit(X<span class="op">=</span>iris.data[:, [<span class="dv">0</span>, <span class="dv">3</span>]])</a>
<a class="sourceLine" id="cb6-6" data-line-number="6"></a>
<a class="sourceLine" id="cb6-7" data-line-number="7"><span class="co"># Associate a colour with each cluster</span></a></code></pre></div>
<div class="sourceCode" id="cb7"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb7-1" data-line-number="1"><span class="im">from</span> palettable.colorbrewer.qualitative <span class="im">import</span> Set1_3</a>
<a class="sourceLine" id="cb7-2" data-line-number="2">colDict <span class="op">=</span> {<span class="dv">0</span>: Set1_3.hex_colors[<span class="dv">0</span>], <span class="dv">1</span>: Set1_3.hex_colors[<span class="dv">1</span>], <span class="dv">2</span>: Set1_3.hex_colors[<span class="dv">2</span>]}</a>
<a class="sourceLine" id="cb7-3" data-line-number="3">myCol <span class="op">=</span> [colDict[i] <span class="cf">for</span> i <span class="kw">in</span> mdl.labels_]</a>
<a class="sourceLine" id="cb7-4" data-line-number="4"></a>
<a class="sourceLine" id="cb7-5" data-line-number="5"><span class="co"># Plot results</span></a>
<a class="sourceLine" id="cb7-6" data-line-number="6"><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</a>
<a class="sourceLine" id="cb7-7" data-line-number="7">plt.scatter(iris.data[:, <span class="dv">3</span>], iris.data[:, <span class="dv">0</span>], c<span class="op">=</span>myCol)</a>
<a class="sourceLine" id="cb7-8" data-line-number="8">plt.xlabel(<span class="st">&#39;Petal width (cm)&#39;</span>)</a>
<a class="sourceLine" id="cb7-9" data-line-number="9">plt.ylabel(<span class="st">&#39;Sepal length (cm)&#39;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-69-1.png" width="480" style="display: block; margin: auto;" /></p>
</div>
<script> javascript:hide('option2unnamed-chunk-15') </script>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Simple and intuitive</td>
<td><span class="math inline">\(k\)</span> needs to be specified <em>a priori</em></td>
</tr>
<tr class="even">
<td>Computationally inexpensive/fast</td>
<td>Only applicable for continuous data where a mean is defined</td>
</tr>
<tr class="odd">
<td></td>
<td>No guarantee of a global optimum solution</td>
</tr>
</tbody>
</table>
</div>
<div id="agglomerative-hiearchical-clustering" class="section level2">
<h2><span class="header-section-number">2.8</span> Agglomerative hiearchical clustering</h2>
<p>In agglomerative hierarchical clustering small clusters are iteratively merged into larger ones. The clustering strategy is as follows:</p>
<ol style="list-style-type: decimal">
<li><p>Assign each datum as its own cluster.</p></li>
<li><p>Compute the distance between each cluster.</p></li>
<li><p>Merge the closest pair into a single cluster.</p></li>
<li><p>Repeat steps 2 to 3 until all clusters are merged together.</p></li>
</ol>
<p>Step 3 is <em>key</em>, the distance metric and <em>linkage</em> function dictate the final result.
The <em>linkage</em> function specifies how the inter-cluster distance is computed. There are various options:</p>
<ul>
<li><p><strong>Centroid</strong>: mean of data points (same as in <span class="math inline">\(k\)</span>-means).
<img src="_img/02-centroid.png" width="300px" style="display: block; margin: auto;" /></p></li>
<li><p><strong>Single</strong>: distance between closest pair of points.
<img src="_img/02-single.png" width="300px" style="display: block; margin: auto;" /></p></li>
<li><p><strong>Complete</strong>: distance between furthest pair of points.
<img src="_img/02-complete.png" width="300px" style="display: block; margin: auto;" /></p></li>
<li><p><strong>Average</strong>: mean pairwise distance between all points.
<img src="_img/02-average.png" width="300px" style="display: block; margin: auto;" /></p></li>
</ul>
<p>The distance can be computed using any <a href="clustering.html#sec:similarity">similarity measure</a> introduced previously.</p>
<div class="tab">
<button class="tablinksunnamed-chunk-20 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-20', 'unnamed-chunk-20');">
R
</button>
<button class="tablinksunnamed-chunk-20" onclick="javascript:openCode(event, 'option2unnamed-chunk-20', 'unnamed-chunk-20');">
Python
</button>
</div>
<div id="option1unnamed-chunk-20" class="tabcontentunnamed-chunk-20">
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1"><span class="co"># Compute distance matrix</span></a>
<a class="sourceLine" id="cb8-2" data-line-number="2">d &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="dt">x=</span>iris[, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">4</span>)], <span class="dt">method=</span><span class="st">&#39;euclidean&#39;</span>) </a>
<a class="sourceLine" id="cb8-3" data-line-number="3"></a>
<a class="sourceLine" id="cb8-4" data-line-number="4"><span class="co"># Perform agglomerative hierarchical clustering</span></a>
<a class="sourceLine" id="cb8-5" data-line-number="5"><span class="co"># Use &#39;average&#39; link function</span></a>
<a class="sourceLine" id="cb8-6" data-line-number="6">mdl &lt;-<span class="st"> </span><span class="kw">hclust</span>(<span class="dt">d=</span>d, <span class="dt">method=</span><span class="st">&#39;average&#39;</span>)</a>
<a class="sourceLine" id="cb8-7" data-line-number="7"></a>
<a class="sourceLine" id="cb8-8" data-line-number="8"><span class="co"># Plot resultant dendrogram</span></a>
<a class="sourceLine" id="cb8-9" data-line-number="9"><span class="kw">plot</span>(mdl, <span class="dt">cex=</span><span class="fl">0.6</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-70-1.png" style="display: block; margin: auto;" /></p>
</div>
<div id="option2unnamed-chunk-20" class="tabcontentunnamed-chunk-20">
<div class="sourceCode" id="cb9"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="im">from</span> scipy.spatial.distance <span class="im">import</span> pdist</a>
<a class="sourceLine" id="cb9-2" data-line-number="2"><span class="im">from</span> scipy.cluster.hierarchy <span class="im">import</span> linkage, dendrogram</a>
<a class="sourceLine" id="cb9-3" data-line-number="3"></a>
<a class="sourceLine" id="cb9-4" data-line-number="4"><span class="co"># Compute distance matrix</span></a>
<a class="sourceLine" id="cb9-5" data-line-number="5">d <span class="op">=</span> pdist(X<span class="op">=</span>iris.data[:, [<span class="dv">0</span>, <span class="dv">3</span>]], metric<span class="op">=</span><span class="st">&quot;euclidean&quot;</span>)</a>
<a class="sourceLine" id="cb9-6" data-line-number="6"></a>
<a class="sourceLine" id="cb9-7" data-line-number="7"><span class="co"># Perform agglomerative hierarchical clustering</span></a>
<a class="sourceLine" id="cb9-8" data-line-number="8"><span class="co"># Use &#39;average&#39; link function</span></a>
<a class="sourceLine" id="cb9-9" data-line-number="9">mdl <span class="op">=</span> linkage(d, method<span class="op">=</span><span class="st">&#39;average&#39;</span>)</a>
<a class="sourceLine" id="cb9-10" data-line-number="10"></a>
<a class="sourceLine" id="cb9-11" data-line-number="11"><span class="co"># Plot resultant dendrogram</span></a>
<a class="sourceLine" id="cb9-12" data-line-number="12">plt.figure(figsize<span class="op">=</span>(<span class="dv">9</span>,<span class="dv">6</span>))</a>
<a class="sourceLine" id="cb9-13" data-line-number="13">dendrogram(mdl)</a></code></pre></div>
<div class="sourceCode" id="cb10"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb10-1" data-line-number="1">plt.show()</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-71-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<script> javascript:hide('option2unnamed-chunk-20') </script>
<p>The number at the end of each branch corresponds to the observation row number.</p>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>No need to specify <span class="math inline">\(k\)</span></td>
<td>Can be computationally expensive</td>
</tr>
<tr class="even">
<td>Sub-groups within larger clusters can be easily identified</td>
<td>Interpretation is subjective. Where should we draw the line?</td>
</tr>
<tr class="odd">
<td>Dendrograms let us visualise results irrespective of number of features</td>
<td>Choice of distance method and linkage function can significantly change the result</td>
</tr>
</tbody>
</table>
</div>
<div id="gaussian-mixture-model-gmm" class="section level2">
<h2><span class="header-section-number">2.9</span> Gaussian mixture model (GMM)</h2>
<p>The GMM is a simple but powerful model that performs clustering via density estimation.
The features’ histogram is modelled as the sum of multiple multivariate Gaussian distributions.
Suppose we only had access to one feature, a GMM with <span class="math inline">\(k=2\)</span> would look something like this:</p>
<p><img src="_img/02-GMM.png" width="600px" style="display: block; margin: auto;" /></p>
<p>The blue dashed lines represent the two individual univariate Gaussians, whilst the black line
depicts the combined model. We can extend this to more features by using multivariate Gaussians.
Mathematically this can be expressed as follows:</p>
<p><span class="math display">\[
p(x) = \sum_{i=1}^k \pi_i \mathcal{N}(x|\mu_i, \Sigma_i)\\
\sum_{i=1}^k \pi_i = 1
\]</span>
The Expectation-Maximisation (EM) algorithm is used to estimate the parameters <span class="math inline">\(\pi_i\)</span> (known as mixing coefficients),
<span class="math inline">\(\mu_i\)</span> and <span class="math inline">\(\Sigma_i\)</span>.</p>
<div class="tab">
<button class="tablinksunnamed-chunk-22 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-22', 'unnamed-chunk-22');">
R
</button>
<button class="tablinksunnamed-chunk-22" onclick="javascript:openCode(event, 'option2unnamed-chunk-22', 'unnamed-chunk-22');">
Python
</button>
</div>
<div id="option1unnamed-chunk-22" class="tabcontentunnamed-chunk-22">
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1"><span class="kw">library</span>(mclust)</a></code></pre></div>
<pre><code>Package &#39;mclust&#39; version 5.4.5
Type &#39;citation(&quot;mclust&quot;)&#39; for citing this R package in publications.</code></pre>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb13-1" data-line-number="1"><span class="co"># Fit Gaussian Mixture Model</span></a>
<a class="sourceLine" id="cb13-2" data-line-number="2">k &lt;-<span class="st"> </span><span class="dv">3</span> <span class="co"># no. of clusters</span></a>
<a class="sourceLine" id="cb13-3" data-line-number="3">mdl &lt;-<span class="st"> </span><span class="kw">Mclust</span>(<span class="dt">data=</span>iris[, <span class="kw">c</span>(<span class="dv">4</span>, <span class="dv">1</span>)], <span class="dt">G=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb13-4" data-line-number="4"></a>
<a class="sourceLine" id="cb13-5" data-line-number="5"><span class="co"># Plot results</span></a>
<a class="sourceLine" id="cb13-6" data-line-number="6"><span class="kw">plot</span>(mdl, <span class="dt">what=</span><span class="st">&#39;classification&#39;</span>,</a>
<a class="sourceLine" id="cb13-7" data-line-number="7">     <span class="dt">xlab=</span><span class="st">&#39;Petal width (cm)&#39;</span>, </a>
<a class="sourceLine" id="cb13-8" data-line-number="8">     <span class="dt">ylab=</span><span class="st">&#39;Sepal length (cm)&#39;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-72-1.png" style="display: block; margin: auto;" /></p>
</div>
<div id="option2unnamed-chunk-22" class="tabcontentunnamed-chunk-22">
<div class="sourceCode" id="cb14"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb14-1" data-line-number="1"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb14-2" data-line-number="2"><span class="im">from</span> matplotlib.colors <span class="im">import</span> LogNorm</a>
<a class="sourceLine" id="cb14-3" data-line-number="3"><span class="im">from</span> sklearn.mixture <span class="im">import</span> GaussianMixture <span class="im">as</span> GMM</a>
<a class="sourceLine" id="cb14-4" data-line-number="4"></a>
<a class="sourceLine" id="cb14-5" data-line-number="5"><span class="co"># Fit Gaussian Mixture Model</span></a>
<a class="sourceLine" id="cb14-6" data-line-number="6">k <span class="op">=</span> <span class="dv">3</span> <span class="co"># no. of clusters</span></a>
<a class="sourceLine" id="cb14-7" data-line-number="7">mdl <span class="op">=</span> GMM(n_components<span class="op">=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb14-8" data-line-number="8">mdl.fit(X<span class="op">=</span>iris.data[:, [<span class="dv">3</span>, <span class="dv">0</span>]])</a>
<a class="sourceLine" id="cb14-9" data-line-number="9"></a>
<a class="sourceLine" id="cb14-10" data-line-number="10"><span class="co"># Compute probability distribution function at each point on a gird</span></a></code></pre></div>
<div class="sourceCode" id="cb15"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb15-1" data-line-number="1">x <span class="op">=</span> np.linspace(np.<span class="bu">min</span>(iris.data[:, <span class="dv">3</span>]), np.<span class="bu">max</span>(iris.data[:, <span class="dv">3</span>]), <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb15-2" data-line-number="2">y <span class="op">=</span> np.linspace(np.<span class="bu">min</span>(iris.data[:, <span class="dv">0</span>]), np.<span class="bu">max</span>(iris.data[:, <span class="dv">0</span>]), <span class="dv">100</span>)</a>
<a class="sourceLine" id="cb15-3" data-line-number="3">X, Y <span class="op">=</span> np.meshgrid(x, y)</a>
<a class="sourceLine" id="cb15-4" data-line-number="4">XX <span class="op">=</span> np.array([X.ravel(), Y.ravel()]).T</a>
<a class="sourceLine" id="cb15-5" data-line-number="5">Z <span class="op">=</span> <span class="op">-</span>mdl.score_samples(XX)</a>
<a class="sourceLine" id="cb15-6" data-line-number="6">Z <span class="op">=</span> Z.reshape(X.shape)</a>
<a class="sourceLine" id="cb15-7" data-line-number="7"></a>
<a class="sourceLine" id="cb15-8" data-line-number="8"><span class="co"># Plot results</span></a>
<a class="sourceLine" id="cb15-9" data-line-number="9">hPlot <span class="op">=</span> plt.contour(X, Y, Z, norm<span class="op">=</span>LogNorm(), </a>
<a class="sourceLine" id="cb15-10" data-line-number="10">                 levels<span class="op">=</span>np.logspace(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">10</span>))</a></code></pre></div>
<div class="sourceCode" id="cb16"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb16-1" data-line-number="1">plt.colorbar(hPlot, shrink<span class="op">=</span><span class="fl">0.8</span>, extend<span class="op">=</span><span class="st">&#39;both&#39;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb17"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb17-1" data-line-number="1">plt.scatter(iris.data[:, <span class="dv">3</span>], iris.data[:, <span class="dv">0</span>])</a>
<a class="sourceLine" id="cb17-2" data-line-number="2">plt.xlabel(<span class="st">&#39;Petal width (cm)&#39;</span>)</a>
<a class="sourceLine" id="cb17-3" data-line-number="3">plt.ylabel(<span class="st">&#39;Sepal length (cm)&#39;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-73-1.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<script> javascript:hide('option2unnamed-chunk-22') </script>
<table>
<colgroup>
<col width="50%" />
<col width="50%" />
</colgroup>
<thead>
<tr class="header">
<th>Pros</th>
<th>Cons</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Intuitive interpretation</td>
<td><span class="math inline">\(k\)</span> needs to be specified <em>a priori</em></td>
</tr>
<tr class="even">
<td>Computationally inexpensive</td>
<td>Strong assumption on the distribution of the feature space (multivariate Gaussian)</td>
</tr>
<tr class="odd">
<td></td>
<td>No guarantee of a global optimum solution</td>
</tr>
<tr class="even">
<td></td>
<td>Fails when number of features is much greater than observations</td>
</tr>
</tbody>
</table>
<p>GMMs offer a “soft” clustering approach, where <em>every</em> observation is part of <em>every</em> cluster but
with varying levels of membership.</p>
</div>
<div id="determining-the-correct-number-of-clusters" class="section level2">
<h2><span class="header-section-number">2.10</span> Determining the “correct” number of clusters</h2>
<p>One of the biggest questions when it comes to clustering is “How many clusters do I have?”.
The number of clusters <span class="math inline">\(k\)</span> cannot be determined <em>exactly</em>, because the observations are
unlabelled, so <span class="math inline">\(k\)</span> is inherently ambiguous. Moreover, similarity is quite subjective
and often we cannot define a clear cut-off.</p>
<p>For example, suppose that as part of a public health exercise we want to cluster
a large group of individuals based on their health. Health is a multifaceted concept
and cannot be observed directly; instead we measure various biomarkers,
like body mass index (BMI), cholesterol levels, body composition,
resting metabolic rate, etc. Although we would be able to differentiate between
individuals at the two extremes (i.e athelete vs couch potato), most people
will sit somewhere on a continuum. There isn’t a clear “line”, that once crossed an individual
goes from being healthy to a bit unhealthy or moderately unhealthy etc. The number
of clusters is therefore somewhat dictated by the problem at hand and the type of questions
we’re trying to answer.</p>
<p>Nevertheless, there are various metrics that one can use to estimate the underlying number of clusters:</p>
<ul>
<li>Recall that the objective of clustering is to minimise the intracluster distance and
maximise the intercluster similarity. Thus, we can plot the within and between clusters sum-of-squares distances
as a function of <span class="math inline">\(k\)</span>. As we increase the number of clusters, there will be a point
where the sum-of-squares distances will only change marginally, that is, adding more
clusters does not improve these metrics significantly. The number of clusters
is chosen to be the point at which the curve “plateaus” (5 in the synthetic example below).
This is known as the “elbow criterion”. Please refer to the <a href="https://www.rdocumentation.org/packages/stats/versions/3.5.3/topics/kmeans">R</a> or
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html">Python</a>
documentation on how to access these metrics.</li>
</ul>
<p><img src="_img/02-SS.png" width="400px" style="display: block; margin: auto;" /></p>
<ul>
<li>The silhouette width quantifies how similar an observation is to its own cluster
compared to other clusters. This measure ranges from -1 (not compatible with that cluster) to 1 (extremely likely to be part of that cluster).
The suggested configuration is the one that maximises the average silhouette width (3 in the synthetic example below).
Please refer to the <a href="https://www.rdocumentation.org/packages/cluster/versions/2.0.7-1/topics/silhouette">R</a> or
<a href="https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py">Python</a> documentation on how to compute and plot these metrics.</li>
</ul>
<p><img src="_img/02-Silhouette.png" width="650px" style="display: block; margin: auto;" /></p>
<ul>
<li>For distribution-based methods, choosing <span class="math inline">\(k\)</span> can be framed as a model selection problem.
We can plot the Akaike Information Criterion (AIC), Bayesian Information Criterior (BIC)
or other information criterion measures.
As we increase the number of clusters, there will be a point
where the model fit will only improve marginally or start to decrease. The number of clusters
is chosen to be the point at which the curve “plateaus”
(the “elbow criterion”; 5 in the synthetic example below).
Please refer to the <a href="https://www.rdocumentation.org/packages/mclust/versions/5.4.3/topics/Mclust">R</a> or
<a href="https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture">Python</a> documentation on how to compute these metrics.</li>
</ul>
<p><img src="_img/02-IC.png" width="400px" style="display: block; margin: auto;" /></p>
<p>There are myriad other metrics available in the literature, some related to specific clustering algorithms.
You will also encounter methods that claim to automatically discover the optimal number of clusters for you.
Although, this can be true in a mathematical sense, this estimate will still be based on various underlying
assumptions and hyperparameters.</p>
<p>These cluster validity measures only give us a <strong>ballpark range</strong>
for the “correct” number of clusters.
Ultimately one needs to make use of prior knowledge to
determine whether the number of clusters are <strong>practically relevant</strong> and if they <strong>make sense</strong>.
For example, how many different phenotypes are you expecting in your population?</p>
</div>
<div id="tasks" class="section level2">
<h2><span class="header-section-number">2.11</span> Tasks</h2>
<div id="simulated-data" class="section level3">
<h3><span class="header-section-number">2.11.1</span> Simulated data</h3>
<p>Let’s start to get a feel for these clustering algorithms by simulating some data:</p>
<div class="tab">
<button class="tablinksunnamed-chunk-26 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-26', 'unnamed-chunk-26');">
R
</button>
<button class="tablinksunnamed-chunk-26" onclick="javascript:openCode(event, 'option2unnamed-chunk-26', 'unnamed-chunk-26');">
Python
</button>
</div>
<div id="option1unnamed-chunk-26" class="tabcontentunnamed-chunk-26">
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1"><span class="kw">library</span>(MASS) <span class="co"># mvrnorm (multivariate normal)</span></a>
<a class="sourceLine" id="cb18-2" data-line-number="2"></a>
<a class="sourceLine" id="cb18-3" data-line-number="3"><span class="co"># Set simulation parameters</span></a>
<a class="sourceLine" id="cb18-4" data-line-number="4">N &lt;-<span class="st"> </span><span class="dv">50</span> <span class="co"># no. of data points in each cluster</span></a>
<a class="sourceLine" id="cb18-5" data-line-number="5">covMatrix &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">data=</span><span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">2</span>), <span class="dt">nrow=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb18-6" data-line-number="6"></a>
<a class="sourceLine" id="cb18-7" data-line-number="7"><span class="co"># Simulate clusters (assume same covariances for now)</span></a>
<a class="sourceLine" id="cb18-8" data-line-number="8"><span class="kw">set.seed</span>(<span class="dv">1034</span>) <span class="co"># to reproduce results</span></a>
<a class="sourceLine" id="cb18-9" data-line-number="9">clustA &lt;-<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n=</span>N, <span class="dt">mu=</span><span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">4</span>), <span class="dt">Sigma=</span>covMatrix)</a>
<a class="sourceLine" id="cb18-10" data-line-number="10">clustB &lt;-<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n=</span>N, <span class="dt">mu=</span><span class="kw">c</span>(<span class="dv">3</span>, <span class="dv">9</span>), <span class="dt">Sigma=</span>covMatrix)</a>
<a class="sourceLine" id="cb18-11" data-line-number="11">clustC &lt;-<span class="st"> </span><span class="kw">mvrnorm</span>(<span class="dt">n=</span>N, <span class="dt">mu=</span><span class="kw">c</span>(<span class="dv">9</span>, <span class="dv">9</span>), <span class="dt">Sigma=</span>covMatrix)</a>
<a class="sourceLine" id="cb18-12" data-line-number="12"></a>
<a class="sourceLine" id="cb18-13" data-line-number="13"><span class="co"># Join all the data together and plot</span></a>
<a class="sourceLine" id="cb18-14" data-line-number="14">xTrain &lt;-<span class="st"> </span><span class="kw">rbind</span>(clustA, clustB, clustC)</a>
<a class="sourceLine" id="cb18-15" data-line-number="15"><span class="kw">plot</span>(xTrain[, <span class="dv">1</span>], xTrain[, <span class="dv">2</span>], <span class="dt">pch=</span><span class="dv">19</span>,</a>
<a class="sourceLine" id="cb18-16" data-line-number="16"><span class="dt">xlab=</span><span class="st">&#39;Feature 1&#39;</span>, <span class="dt">ylab=</span><span class="st">&#39;Feature 2&#39;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-74-1.png" style="display: block; margin: auto;" /></p>
</div>
<div id="option2unnamed-chunk-26" class="tabcontentunnamed-chunk-26">
<div class="sourceCode" id="cb19"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb19-1" data-line-number="1"><span class="im">from</span> numpy.random <span class="im">import</span> multivariate_normal, seed</a>
<a class="sourceLine" id="cb19-2" data-line-number="2"></a>
<a class="sourceLine" id="cb19-3" data-line-number="3"><span class="co"># Set simulation parameters</span></a>
<a class="sourceLine" id="cb19-4" data-line-number="4">N <span class="op">=</span> <span class="dv">50</span> <span class="co"># no. of data points in each cluster</span></a>
<a class="sourceLine" id="cb19-5" data-line-number="5">covMatrix <span class="op">=</span> np.array([[<span class="dv">1</span>, <span class="dv">0</span>], [<span class="dv">0</span>, <span class="dv">2</span>]], dtype<span class="op">=</span><span class="st">&#39;float&#39;</span>)</a>
<a class="sourceLine" id="cb19-6" data-line-number="6"></a>
<a class="sourceLine" id="cb19-7" data-line-number="7"><span class="co"># Simulate clusters (assume same covariances for now)</span></a>
<a class="sourceLine" id="cb19-8" data-line-number="8">seed(<span class="dv">1034</span>) <span class="co"># to reproduce results</span></a>
<a class="sourceLine" id="cb19-9" data-line-number="9">clustA <span class="op">=</span> multivariate_normal(mean<span class="op">=</span>np.array([<span class="dv">6</span>, <span class="dv">4</span>]), cov<span class="op">=</span>covMatrix, size<span class="op">=</span>N)</a>
<a class="sourceLine" id="cb19-10" data-line-number="10">clustB <span class="op">=</span> multivariate_normal(mean<span class="op">=</span>np.array([<span class="dv">3</span>, <span class="dv">9</span>]), cov<span class="op">=</span>covMatrix, size<span class="op">=</span>N)</a>
<a class="sourceLine" id="cb19-11" data-line-number="11">clustC <span class="op">=</span> multivariate_normal(mean<span class="op">=</span>np.array([<span class="dv">9</span>, <span class="dv">9</span>]), cov<span class="op">=</span>covMatrix, size<span class="op">=</span>N)</a>
<a class="sourceLine" id="cb19-12" data-line-number="12"></a>
<a class="sourceLine" id="cb19-13" data-line-number="13"><span class="co"># Join all the data together and plot</span></a>
<a class="sourceLine" id="cb19-14" data-line-number="14">xTrain <span class="op">=</span> np.vstack((clustA, clustB, clustC))</a>
<a class="sourceLine" id="cb19-15" data-line-number="15">plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">6</span>))</a>
<a class="sourceLine" id="cb19-16" data-line-number="16">plt.scatter(xTrain[:, <span class="dv">0</span>], xTrain[:, <span class="dv">1</span>])</a>
<a class="sourceLine" id="cb19-17" data-line-number="17">plt.xlabel(<span class="st">&#39;Feature 1&#39;</span>)</a>
<a class="sourceLine" id="cb19-18" data-line-number="18">plt.ylabel(<span class="st">&#39;Feature 2&#39;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-75-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<script> javascript:hide('option2unnamed-chunk-26') </script>
<div class="panel panel-default">
<div class="panel-heading">
Task
</div>
<div class="panel-body">
<ul>
<li><p>Perform <span class="math inline">\(k\)</span>-means clustering by allowing <span class="math inline">\(k\)</span> to vary from 2 to 6 .</p></li>
<li>Plot the intra and intercluster sum-of-squares as a function of <span class="math inline">\(k\)</span> and deduce the
“true” number of underlying clusters.
</div>
</div></li>
</ul>
<button id="displayTextunnamed-chunk-28" onclick="javascript:toggle('unnamed-chunk-28');">
Show Solution
</button>
<div id="toggleTextunnamed-chunk-28" style="display: none">
<div class="panel panel-default">
<div class="panel-heading panel-heading1">
Solution
</div>
<div class="panel-body">
<div class="tab">
<button class="tablinksunnamed-chunk-28 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-28', 'unnamed-chunk-28');">
R
</button>
<button class="tablinksunnamed-chunk-28" onclick="javascript:openCode(event, 'option2unnamed-chunk-28', 'unnamed-chunk-28');">
Python
</button>
</div>
<div id="option1unnamed-chunk-28" class="tabcontentunnamed-chunk-28">
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="co"># Initialise some variables</span></a>
<a class="sourceLine" id="cb20-2" data-line-number="2">kRange &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from=</span><span class="dv">2</span>, <span class="dt">to=</span><span class="dv">6</span>, <span class="dt">by=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb20-3" data-line-number="3">intra &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">length</span>(kRange)) <span class="co"># intracluster sum-of-squares</span></a>
<a class="sourceLine" id="cb20-4" data-line-number="4">inter &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">length</span>(kRange)) <span class="co"># intercluster sum-of-squares</span></a>
<a class="sourceLine" id="cb20-5" data-line-number="5"></a>
<a class="sourceLine" id="cb20-6" data-line-number="6"><span class="co"># Loop across desired range of ks</span></a>
<a class="sourceLine" id="cb20-7" data-line-number="7"><span class="cf">for</span> (k <span class="cf">in</span> kRange) {</a>
<a class="sourceLine" id="cb20-8" data-line-number="8">    mdl &lt;-<span class="st"> </span><span class="kw">kmeans</span>(<span class="dt">x=</span>xTrain , <span class="dt">centers=</span>k)</a>
<a class="sourceLine" id="cb20-9" data-line-number="9">    intra[k<span class="dv">-1</span>] &lt;-<span class="st"> </span>mdl<span class="op">$</span>tot.withinss <span class="co"># it’s (k-1) because k starts from 2</span></a>
<a class="sourceLine" id="cb20-10" data-line-number="10">    inter[k<span class="dv">-1</span>] &lt;-<span class="st"> </span>mdl<span class="op">$</span>betweenss </a>
<a class="sourceLine" id="cb20-11" data-line-number="11">}</a>
<a class="sourceLine" id="cb20-12" data-line-number="12"></a>
<a class="sourceLine" id="cb20-13" data-line-number="13"><span class="co"># Plot inter/intercluster sum-of-squares as a function of $k$</span></a>
<a class="sourceLine" id="cb20-14" data-line-number="14">yMin &lt;-<span class="st"> </span><span class="kw">min</span>(<span class="kw">c</span>(intra , inter)) </a>
<a class="sourceLine" id="cb20-15" data-line-number="15">yMax &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw">c</span>(intra , inter))</a>
<a class="sourceLine" id="cb20-16" data-line-number="16"><span class="kw">plot</span>(kRange, inter, <span class="dt">type=</span><span class="st">&quot;o&quot;</span>, <span class="dt">pch=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">lty=</span><span class="dv">1</span>, </a>
<a class="sourceLine" id="cb20-17" data-line-number="17"><span class="dt">ylim=</span><span class="kw">c</span>(yMin, yMax), <span class="dt">xlab=</span><span class="st">&quot;k&quot;</span>, <span class="dt">ylab=</span><span class="st">&#39;Sum-of-squares&#39;</span>)</a>
<a class="sourceLine" id="cb20-18" data-line-number="18"><span class="kw">points</span>(kRange, intra, <span class="dt">type=</span><span class="st">&quot;o&quot;</span>, <span class="dt">pch=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb20-19" data-line-number="19"><span class="kw">legend</span>(<span class="st">&quot;right&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;inter-cluster&quot;</span>, <span class="st">&quot;intra-cluster&quot;</span>), </a>
<a class="sourceLine" id="cb20-20" data-line-number="20"><span class="dt">bty=</span><span class="st">&quot;n&quot;</span>, <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="dt">pch=</span><span class="dv">1</span>, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">lty=</span><span class="dv">1</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-76-1.png" style="display: block; margin: auto;" /></p>
<p>The “correct” number of clusters is approximately 3.
This matches our expectation.</p>
</div>
<div id="option2unnamed-chunk-28" class="tabcontentunnamed-chunk-28">
<div class="sourceCode" id="cb21"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb21-1" data-line-number="1"><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> scale</a>
<a class="sourceLine" id="cb21-2" data-line-number="2"></a>
<a class="sourceLine" id="cb21-3" data-line-number="3"><span class="co"># Initialise some variables</span></a>
<a class="sourceLine" id="cb21-4" data-line-number="4">kRange <span class="op">=</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">7</span>)</a>
<a class="sourceLine" id="cb21-5" data-line-number="5">intra <span class="op">=</span> np.empty(<span class="bu">len</span>(kRange)) <span class="co"># intracluster sum-of-squares</span></a>
<a class="sourceLine" id="cb21-6" data-line-number="6">inter <span class="op">=</span> np.empty(<span class="bu">len</span>(kRange)) <span class="co"># intercluster sum-of-squares</span></a>
<a class="sourceLine" id="cb21-7" data-line-number="7"></a>
<a class="sourceLine" id="cb21-8" data-line-number="8"><span class="co"># Loop across desired range of ks</span></a>
<a class="sourceLine" id="cb21-9" data-line-number="9"><span class="cf">for</span> k <span class="kw">in</span> kRange:</a>
<a class="sourceLine" id="cb21-10" data-line-number="10">    mdl <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k)</a>
<a class="sourceLine" id="cb21-11" data-line-number="11">    mdl.fit(X<span class="op">=</span>xTrain)</a>
<a class="sourceLine" id="cb21-12" data-line-number="12">    intra[k<span class="dv">-2</span>] <span class="op">=</span> mdl.inertia_  <span class="co"># it’s (k-2) because k starts from 2</span></a>
<a class="sourceLine" id="cb21-13" data-line-number="13">    inter[k<span class="dv">-2</span>] <span class="op">=</span> np.<span class="bu">sum</span>(scale(xTrain, with_std<span class="op">=</span><span class="va">False</span>)<span class="op">**</span><span class="dv">2</span>) <span class="op">-</span> mdl.inertia_</a>
<a class="sourceLine" id="cb21-14" data-line-number="14"></a>
<a class="sourceLine" id="cb21-15" data-line-number="15"><span class="co"># Plot inter/intercluster sum-of-squares as a function of $k$</span></a></code></pre></div>
<div class="sourceCode" id="cb22"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb22-1" data-line-number="1">plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">5</span>))</a>
<a class="sourceLine" id="cb22-2" data-line-number="2">plt.plot(kRange, inter, <span class="st">&#39;bo-&#39;</span>, label<span class="op">=</span><span class="st">&#39;inter-cluster&#39;</span>)</a>
<a class="sourceLine" id="cb22-3" data-line-number="3">plt.plot(kRange, intra, <span class="st">&#39;ro-&#39;</span>, label<span class="op">=</span><span class="st">&#39;intra-cluster&#39;</span>)</a>
<a class="sourceLine" id="cb22-4" data-line-number="4">plt.legend(loc<span class="op">=</span><span class="st">&#39;center right&#39;</span>)</a>
<a class="sourceLine" id="cb22-5" data-line-number="5">plt.xlabel(<span class="st">&#39;k&#39;</span>)</a>
<a class="sourceLine" id="cb22-6" data-line-number="6">plt.ylabel(<span class="st">&#39;Sum-of-squares&#39;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-77-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>The “correct” number of clusters is approximately 3.
This matches our expectation.</p>
</div>
<script> javascript:hide('option2unnamed-chunk-28') </script>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
Task
</div>
<div class="panel-body">
<ul>
<li><p>Fit a Gaussian Mixture Model (GMM) by allowing <span class="math inline">\(k\)</span> to vary from 2 to 6 .</p></li>
<li>Plot the AIC and BIC as a function of <span class="math inline">\(k\)</span> and deduce the “true” number of underlying clusters.
</div>
</div></li>
</ul>
<button id="displayTextunnamed-chunk-30" onclick="javascript:toggle('unnamed-chunk-30');">
Show Solution
</button>
<div id="toggleTextunnamed-chunk-30" style="display: none">
<div class="panel panel-default">
<div class="panel-heading panel-heading1">
Solution
</div>
<div class="panel-body">
<div class="tab">
<button class="tablinksunnamed-chunk-30 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-30', 'unnamed-chunk-30');">
R
</button>
<button class="tablinksunnamed-chunk-30" onclick="javascript:openCode(event, 'option2unnamed-chunk-30', 'unnamed-chunk-30');">
Python
</button>
</div>
<div id="option1unnamed-chunk-30" class="tabcontentunnamed-chunk-30">
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb23-1" data-line-number="1"><span class="co"># Initialise some variables</span></a>
<a class="sourceLine" id="cb23-2" data-line-number="2">kRange &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from=</span><span class="dv">2</span>, <span class="dt">to=</span><span class="dv">6</span>, <span class="dt">by=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb23-3" data-line-number="3">AIC &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">length</span>(kRange)) <span class="co"># Akaike information criterion</span></a>
<a class="sourceLine" id="cb23-4" data-line-number="4">BIC &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">length</span>(kRange)) <span class="co"># Bayesian information criterion</span></a>
<a class="sourceLine" id="cb23-5" data-line-number="5"></a>
<a class="sourceLine" id="cb23-6" data-line-number="6"></a>
<a class="sourceLine" id="cb23-7" data-line-number="7"><span class="co"># Loop across desired range of ks</span></a>
<a class="sourceLine" id="cb23-8" data-line-number="8"><span class="cf">for</span> (k <span class="cf">in</span> kRange) {</a>
<a class="sourceLine" id="cb23-9" data-line-number="9">    mdl &lt;-<span class="st"> </span><span class="kw">Mclust</span>(<span class="dt">data=</span>xTrain, <span class="dt">G=</span>k)</a>
<a class="sourceLine" id="cb23-10" data-line-number="10">    AIC[k<span class="dv">-1</span>] &lt;-<span class="st"> </span><span class="dv">2</span><span class="op">*</span>mdl<span class="op">$</span>loglik <span class="op">-</span><span class="st"> </span><span class="dv">2</span><span class="op">*</span>mdl<span class="op">$</span>df</a>
<a class="sourceLine" id="cb23-11" data-line-number="11">    BIC[k<span class="dv">-1</span>] &lt;-<span class="st"> </span>mdl<span class="op">$</span>bic</a>
<a class="sourceLine" id="cb23-12" data-line-number="12">}</a>
<a class="sourceLine" id="cb23-13" data-line-number="13"></a>
<a class="sourceLine" id="cb23-14" data-line-number="14"><span class="co"># Plot inter/intercluster sum-of-squares as a function of $k$</span></a>
<a class="sourceLine" id="cb23-15" data-line-number="15">yMin &lt;-<span class="st"> </span><span class="kw">min</span>(<span class="kw">c</span>(AIC , BIC)) </a>
<a class="sourceLine" id="cb23-16" data-line-number="16">yMax &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw">c</span>(AIC , BIC))</a>
<a class="sourceLine" id="cb23-17" data-line-number="17"><span class="kw">plot</span>(kRange, AIC, <span class="dt">type=</span><span class="st">&quot;o&quot;</span>, <span class="dt">pch=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">lty=</span><span class="dv">1</span>, </a>
<a class="sourceLine" id="cb23-18" data-line-number="18"><span class="dt">ylim=</span><span class="kw">c</span>(yMin, yMax), <span class="dt">xlab=</span><span class="st">&quot;k&quot;</span>, <span class="dt">ylab=</span><span class="st">&#39;Information criterion&#39;</span>)</a>
<a class="sourceLine" id="cb23-19" data-line-number="19"><span class="kw">points</span>(kRange, BIC, <span class="dt">type=</span><span class="st">&quot;o&quot;</span>, <span class="dt">pch=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb23-20" data-line-number="20"><span class="kw">legend</span>(<span class="st">&quot;right&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;AIC&quot;</span>, <span class="st">&quot;BIC&quot;</span>), </a>
<a class="sourceLine" id="cb23-21" data-line-number="21"><span class="dt">bty=</span><span class="st">&quot;n&quot;</span>, <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="dt">pch=</span><span class="dv">1</span>, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">lty=</span><span class="dv">1</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-78-1.png" style="display: block; margin: auto;" /></p>
<p>The “correct” number of clusters is approximately 3.
This matches our expectation.</p>
</div>
<div id="option2unnamed-chunk-30" class="tabcontentunnamed-chunk-30">
<div class="sourceCode" id="cb24"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb24-1" data-line-number="1"><span class="co"># Initialise some variables</span></a>
<a class="sourceLine" id="cb24-2" data-line-number="2">kRange <span class="op">=</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">7</span>)</a>
<a class="sourceLine" id="cb24-3" data-line-number="3">AIC <span class="op">=</span> np.empty(<span class="bu">len</span>(kRange)) <span class="co"># Akaike information criterion</span></a>
<a class="sourceLine" id="cb24-4" data-line-number="4">BIC <span class="op">=</span> np.empty(<span class="bu">len</span>(kRange)) <span class="co"># Bayesian information criterion</span></a>
<a class="sourceLine" id="cb24-5" data-line-number="5"></a>
<a class="sourceLine" id="cb24-6" data-line-number="6"><span class="co"># Loop across desired range of ks</span></a>
<a class="sourceLine" id="cb24-7" data-line-number="7"><span class="cf">for</span> k <span class="kw">in</span> kRange:</a>
<a class="sourceLine" id="cb24-8" data-line-number="8">    mdl <span class="op">=</span> GMM(n_components<span class="op">=</span>k)</a>
<a class="sourceLine" id="cb24-9" data-line-number="9">    mdl.fit(X<span class="op">=</span>xTrain)</a>
<a class="sourceLine" id="cb24-10" data-line-number="10">    AIC[k<span class="dv">-2</span>] <span class="op">=</span> <span class="op">-</span>mdl.aic(xTrain)</a>
<a class="sourceLine" id="cb24-11" data-line-number="11">    BIC[k<span class="dv">-2</span>] <span class="op">=</span> <span class="op">-</span>mdl.bic(xTrain)</a>
<a class="sourceLine" id="cb24-12" data-line-number="12"></a>
<a class="sourceLine" id="cb24-13" data-line-number="13"><span class="co"># Plot inter/intercluster sum-of-squares as a function of $k$</span></a></code></pre></div>
<div class="sourceCode" id="cb25"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb25-1" data-line-number="1">plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">6</span>))</a>
<a class="sourceLine" id="cb25-2" data-line-number="2">plt.plot(kRange, AIC, <span class="st">&#39;bo-&#39;</span>, label<span class="op">=</span><span class="st">&#39;AIC&#39;</span>)</a>
<a class="sourceLine" id="cb25-3" data-line-number="3">plt.plot(kRange, BIC, <span class="st">&#39;ro-&#39;</span>, label<span class="op">=</span><span class="st">&#39;BIC&#39;</span>)</a>
<a class="sourceLine" id="cb25-4" data-line-number="4">plt.legend(loc<span class="op">=</span><span class="st">&#39;center right&#39;</span>)</a>
<a class="sourceLine" id="cb25-5" data-line-number="5">plt.xlabel(<span class="st">&#39;k&#39;</span>)</a>
<a class="sourceLine" id="cb25-6" data-line-number="6">plt.ylabel(<span class="st">&#39;Information criterion&#39;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-79-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>The “correct” number of clusters is approximately 3.
This matches our expectation.</p>
</div>
<script> javascript:hide('option2unnamed-chunk-30') </script>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
Task
</div>
<div class="panel-body">
Perform the above analysis on several sets of simulated data by changing the mean
and covariance matrix of each simulated cluster. Try bringing the clusters closer
together and then push them further apart. What happens to intra/intercluster distance
and AIC/BIC plots?
</div>
</div>
<button id="displayTextunnamed-chunk-32" onclick="javascript:toggle('unnamed-chunk-32');">
Show Solution
</button>
<div id="toggleTextunnamed-chunk-32" style="display: none">
<div class="panel panel-default">
<div class="panel-heading panel-heading1">
Solution
</div>
<div class="panel-body">
<ul>
<li><p>As clusters move closer together, the “elbow” becomes less
pronounced due to the large overlap between clusters. The
“correct” number of clusters will inevitably become more ambiguous.</p></li>
<li>As clusters move further apart, the “elbow” becomes more
pronounced, making it easier to determine the “correct” number of clusters.
Note, however, that we could still have sub-groups within a particular cluster;
it’s just that the within-cluster dissimilarity would be subtle compared to the across-clusters
dissimilarity. For example, if one were to cluster a large set
of images containing dogs, cats and horses, you would expect to find three distinct
clusters. However, we know that within the dogs cluster you’d also have sub-clusters
related to different species of dogs.
</div>
</div>
</div></li>
</ul>
</div>
<div id="gene-expression" class="section level3">
<h3><span class="header-section-number">2.11.2</span> Gene expression</h3>
<p>The file <code>gene_expression.csv</code> (all workshop datasets are available <a href="https://exeter-data-analytics.github.io/MachineLearning/data.zip">here</a>),
contains the acute lymphoblastic leukaemia (ALL) dataset which was published in the following study
(see <a href="http://www.bloodjournal.org/content/103/7/2771">here</a> and <a href="http://clincancerres.aacrjournals.org/content/11/20/7209">here</a>).
The dataset contains <em>normalised</em> gene expression values (measured using microarray) for 128 patients
and 12,625 genes. The patients were diagnosed with either a B- or T-cell acute lymphocytic leukaemia.</p>
<p>Do not worry too much about the details (i.e what the genes are etc.),
treat this dataset as a <span class="math inline">\(G \times N\)</span> matrix where <span class="math inline">\(G\)</span> is the total number of genes
and <span class="math inline">\(N\)</span> is the number of patients.
We have access to the labels, type and stage of the disease (e.g B2). Thus, we can easily
assess how well the clustering algorithm is doing, as we expect the B’s and T’s to cluster together.</p>
<div class="tab">
<button class="tablinksunnamed-chunk-33 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-33', 'unnamed-chunk-33');">
R
</button>
<button class="tablinksunnamed-chunk-33" onclick="javascript:openCode(event, 'option2unnamed-chunk-33', 'unnamed-chunk-33');">
Python
</button>
</div>
<div id="option1unnamed-chunk-33" class="tabcontentunnamed-chunk-33">
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb26-1" data-line-number="1">xTrain &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;_data/gene_expression.csv&#39;</span>, <span class="dt">row.names=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb26-2" data-line-number="2"><span class="kw">print</span>(<span class="kw">dim</span>(xTrain))</a></code></pre></div>
<pre><code>[1] 12625   128</code></pre>
</div>
<div id="option2unnamed-chunk-33" class="tabcontentunnamed-chunk-33">
<div class="sourceCode" id="cb28"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb28-1" data-line-number="1"><span class="im">import</span> pandas <span class="im">as</span> pd</a>
<a class="sourceLine" id="cb28-2" data-line-number="2"></a>
<a class="sourceLine" id="cb28-3" data-line-number="3">xTrain <span class="op">=</span> pd.read_csv(<span class="st">&#39;_data/gene_expression.csv&#39;</span>, header<span class="op">=</span><span class="dv">0</span>, index_col<span class="op">=</span><span class="dv">0</span>)</a>
<a class="sourceLine" id="cb28-4" data-line-number="4"><span class="bu">print</span>(xTrain.shape)</a></code></pre></div>
<pre><code>(12625, 128)</code></pre>
</div>
<script> javascript:hide('option2unnamed-chunk-33') </script>
<div class="panel panel-default">
<div class="panel-heading">
Task
</div>
<div class="panel-body">
Perform agglomerative hierarchical clustering on the 128 patients. Keep the distance
method as <code>euclidean</code>, but change the linkage method (e.g single, average) and
observe how the dendrogram changes.
</div>
</div>
<button id="displayTextunnamed-chunk-35" onclick="javascript:toggle('unnamed-chunk-35');">
Show Solution
</button>
<div id="toggleTextunnamed-chunk-35" style="display: none">
<div class="panel panel-default">
<div class="panel-heading panel-heading1">
Solution
</div>
<div class="panel-body">
<div class="tab">
<button class="tablinksunnamed-chunk-35 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-35', 'unnamed-chunk-35');">
R
</button>
<button class="tablinksunnamed-chunk-35" onclick="javascript:openCode(event, 'option2unnamed-chunk-35', 'unnamed-chunk-35');">
Python
</button>
</div>
<div id="option1unnamed-chunk-35" class="tabcontentunnamed-chunk-35">
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb30-1" data-line-number="1">linkMethods &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;single&#39;</span>, <span class="st">&#39;complete&#39;</span>, <span class="st">&#39;average&#39;</span>)</a>
<a class="sourceLine" id="cb30-2" data-line-number="2">distMethod &lt;-<span class="st"> &#39;euclidean&#39;</span></a>
<a class="sourceLine" id="cb30-3" data-line-number="3">distance &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="kw">as.matrix</span>(<span class="kw">t</span>(xTrain), <span class="dt">method=</span>distMethod))</a>
<a class="sourceLine" id="cb30-4" data-line-number="4"><span class="cf">for</span> (linkMethod <span class="cf">in</span> linkMethods) {</a>
<a class="sourceLine" id="cb30-5" data-line-number="5">    mdl &lt;-<span class="st"> </span><span class="kw">hclust</span>(distance , <span class="dt">method=</span>linkMethod)</a>
<a class="sourceLine" id="cb30-6" data-line-number="6">    <span class="kw">plot</span>(mdl, <span class="dt">cex=</span><span class="fl">0.5</span>, <span class="dt">xlab=</span><span class="st">&#39;distance&#39;</span>, </a>
<a class="sourceLine" id="cb30-7" data-line-number="7">    <span class="dt">main=</span><span class="kw">paste0</span>(distMethod, <span class="st">&#39; distance and &#39;</span>, linkMethod, <span class="st">&#39; link function&#39;</span>))</a>
<a class="sourceLine" id="cb30-8" data-line-number="8">}</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-82-1.png" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-82-2.png" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-82-3.png" style="display: block; margin: auto;" /></p>
</div>
<div id="option2unnamed-chunk-35" class="tabcontentunnamed-chunk-35">
<div class="sourceCode" id="cb31"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb31-1" data-line-number="1">linkMethods <span class="op">=</span> [<span class="st">&#39;single&#39;</span>, <span class="st">&#39;complete&#39;</span>, <span class="st">&#39;average&#39;</span>]</a>
<a class="sourceLine" id="cb31-2" data-line-number="2">distMethod <span class="op">=</span> <span class="st">&#39;euclidean&#39;</span></a>
<a class="sourceLine" id="cb31-3" data-line-number="3">distance <span class="op">=</span> pdist(X<span class="op">=</span>xTrain.T, metric<span class="op">=</span>distMethod )</a>
<a class="sourceLine" id="cb31-4" data-line-number="4"><span class="cf">for</span> linkMethod <span class="kw">in</span> linkMethods:</a>
<a class="sourceLine" id="cb31-5" data-line-number="5">    mdl <span class="op">=</span> linkage(distance, method<span class="op">=</span>linkMethod)</a>
<a class="sourceLine" id="cb31-6" data-line-number="6">    plt.figure(num<span class="op">=</span>linkMethod, figsize<span class="op">=</span>(<span class="dv">9</span>,<span class="dv">6</span>))</a>
<a class="sourceLine" id="cb31-7" data-line-number="7">    dendrogram(mdl)</a>
<a class="sourceLine" id="cb31-8" data-line-number="8">    plt.title(<span class="st">&#39;</span><span class="sc">{0}</span><span class="st"> distance and </span><span class="sc">{1}</span><span class="st"> link function&#39;</span>.<span class="bu">format</span>(distMethod, linkMethod))</a>
<a class="sourceLine" id="cb31-9" data-line-number="9">    plt.show()</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-83-1.png" width="864" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-83-2.png" width="864" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-83-3.png" width="864" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-83-4.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<script> javascript:hide('option2unnamed-chunk-35') </script>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
Task
</div>
<div class="panel-body">
Same as before, but now keep the linkage method as <code>average</code> and change
the distance method (e.g euclidean, manhattan) and observe how the dendrogram changes.
</div>
</div>
<button id="displayTextunnamed-chunk-37" onclick="javascript:toggle('unnamed-chunk-37');">
Show Solution
</button>
<div id="toggleTextunnamed-chunk-37" style="display: none">
<div class="panel panel-default">
<div class="panel-heading panel-heading1">
Solution
</div>
<div class="panel-body">
<div class="tab">
<button class="tablinksunnamed-chunk-37 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-37', 'unnamed-chunk-37');">
R
</button>
<button class="tablinksunnamed-chunk-37" onclick="javascript:openCode(event, 'option2unnamed-chunk-37', 'unnamed-chunk-37');">
Python
</button>
</div>
<div id="option1unnamed-chunk-37" class="tabcontentunnamed-chunk-37">
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb32-1" data-line-number="1">linkMethod &lt;-<span class="st"> &#39;average&#39;</span></a>
<a class="sourceLine" id="cb32-2" data-line-number="2">distMethods &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;euclidean&#39;</span>, <span class="st">&#39;manhattan&#39;</span>, <span class="st">&#39;canberra&#39;</span>)</a>
<a class="sourceLine" id="cb32-3" data-line-number="3"><span class="cf">for</span> (distMethod <span class="cf">in</span> distMethods) {</a>
<a class="sourceLine" id="cb32-4" data-line-number="4">    distance &lt;-<span class="st"> </span><span class="kw">dist</span>(<span class="kw">as.matrix</span>(<span class="kw">t</span>(xTrain), <span class="dt">method=</span>distMethod))</a>
<a class="sourceLine" id="cb32-5" data-line-number="5">    mdl &lt;-<span class="st"> </span><span class="kw">hclust</span>(distance , <span class="dt">method=</span>linkMethod)</a>
<a class="sourceLine" id="cb32-6" data-line-number="6">    <span class="kw">plot</span>(mdl, <span class="dt">cex=</span><span class="fl">0.5</span>, <span class="dt">xlab=</span><span class="st">&#39;distance&#39;</span>, </a>
<a class="sourceLine" id="cb32-7" data-line-number="7">    <span class="dt">main=</span><span class="kw">paste0</span>(distMethod, <span class="st">&#39; distance and &#39;</span>, linkMethod, <span class="st">&#39; link function&#39;</span>))</a>
<a class="sourceLine" id="cb32-8" data-line-number="8">}</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-84-1.png" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-84-2.png" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-84-3.png" style="display: block; margin: auto;" /></p>
</div>
<div id="option2unnamed-chunk-37" class="tabcontentunnamed-chunk-37">
<div class="sourceCode" id="cb33"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb33-1" data-line-number="1">linkMethod <span class="op">=</span> <span class="st">&#39;average&#39;</span></a>
<a class="sourceLine" id="cb33-2" data-line-number="2">distMethods <span class="op">=</span> [<span class="st">&#39;euclidean&#39;</span>, <span class="st">&#39;cityblock&#39;</span>, <span class="st">&#39;canberra&#39;</span>]</a>
<a class="sourceLine" id="cb33-3" data-line-number="3"><span class="cf">for</span> distMethod <span class="kw">in</span> distMethods:</a>
<a class="sourceLine" id="cb33-4" data-line-number="4">    distance <span class="op">=</span> pdist(X<span class="op">=</span>xTrain.T, metric<span class="op">=</span>distMethod )</a>
<a class="sourceLine" id="cb33-5" data-line-number="5">    mdl <span class="op">=</span> linkage(distance, method<span class="op">=</span>linkMethod)</a>
<a class="sourceLine" id="cb33-6" data-line-number="6">    plt.figure(num<span class="op">=</span>distMethod, figsize<span class="op">=</span>(<span class="dv">9</span>,<span class="dv">6</span>))</a>
<a class="sourceLine" id="cb33-7" data-line-number="7">    dendrogram(mdl)</a>
<a class="sourceLine" id="cb33-8" data-line-number="8">    plt.title(<span class="st">&#39;</span><span class="sc">{0}</span><span class="st"> distance and </span><span class="sc">{1}</span><span class="st"> link function&#39;</span>.<span class="bu">format</span>(distMethod, linkMethod))</a>
<a class="sourceLine" id="cb33-9" data-line-number="9">    plt.show()</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-85-1.png" width="864" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-85-2.png" width="864" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-85-3.png" width="864" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-85-4.png" width="864" style="display: block; margin: auto;" /></p>
</div>
<script> javascript:hide('option2unnamed-chunk-37') </script>
</div>
</div>
</div>
</div>
<div id="wine" class="section level3">
<h3><span class="header-section-number">2.11.3</span> Wine</h3>
<p>The file <code>wine.csv</code> contains chemical analysis data of wines grown in the <em>same</em> region
in Italy but from three different cultivars (see <a href="https://archive.ics.uci.edu/ml/datasets/Wine">here</a> for details).</p>
<div class="tab">
<button class="tablinksunnamed-chunk-38 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-38', 'unnamed-chunk-38');">
R
</button>
<button class="tablinksunnamed-chunk-38" onclick="javascript:openCode(event, 'option2unnamed-chunk-38', 'unnamed-chunk-38');">
Python
</button>
</div>
<div id="option1unnamed-chunk-38" class="tabcontentunnamed-chunk-38">
<div class="sourceCode" id="cb34"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb34-1" data-line-number="1">xTrain &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&#39;_data/wine.csv&#39;</span>)</a>
<a class="sourceLine" id="cb34-2" data-line-number="2"><span class="kw">print</span>(<span class="kw">head</span>(xTrain))</a></code></pre></div>
<pre><code>  WineType Alcohol MalicAcid  Ash AlcalinityAsh Magnesium TotalPhenols
1        A   14.23      1.71 2.43          15.6       127         2.80
2        A   13.20      1.78 2.14          11.2       100         2.65
3        A   13.16      2.36 2.67          18.6       101         2.80
4        A   14.37      1.95 2.50          16.8       113         3.85
5        A   13.24      2.59 2.87          21.0       118         2.80
6        A   14.20      1.76 2.45          15.2       112         3.27
  Flavanoids NonflavanoidPhenols Proanthocyanins ColorIntensity  Hue
1       3.06                0.28            2.29           5.64 1.04
2       2.76                0.26            1.28           4.38 1.05
3       3.24                0.30            2.81           5.68 1.03
4       3.49                0.24            2.18           7.80 0.86
5       2.69                0.39            1.82           4.32 1.04
6       3.39                0.34            1.97           6.75 1.05
  OD280_OD315 Proline
1        3.92    1065
2        3.40    1050
3        3.17    1185
4        3.45    1480
5        2.93     735
6        2.85    1450</code></pre>
</div>
<div id="option2unnamed-chunk-38" class="tabcontentunnamed-chunk-38">
<div class="sourceCode" id="cb36"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb36-1" data-line-number="1">xTrain <span class="op">=</span> pd.read_csv(<span class="st">&#39;_data/wine.csv&#39;</span>, header<span class="op">=</span><span class="dv">0</span>)</a>
<a class="sourceLine" id="cb36-2" data-line-number="2"><span class="bu">print</span>(xTrain.head())</a></code></pre></div>
<pre><code>  WineType  Alcohol  MalicAcid  ...   Hue  OD280_OD315  Proline
0        A    14.23       1.71  ...  1.04         3.92     1065
1        A    13.20       1.78  ...  1.05         3.40     1050
2        A    13.16       2.36  ...  1.03         3.17     1185
3        A    14.37       1.95  ...  0.86         3.45     1480
4        A    13.24       2.59  ...  1.04         2.93      735

[5 rows x 14 columns]</code></pre>
</div>
<script> javascript:hide('option2unnamed-chunk-38') </script>
<p>There are thirteen variables (<code>Alcohol</code>, <code>MalicAcid</code>, etc.), together with <code>WineType</code>, which specifies the type of wine.
Here, we are going to pretend we do not know that there are three types of wine, instead we’ll use
clustering methods to uncover this information.</p>
<p>One thing to notice with this data, is that the units vary greatly across variables. For example, <code>Proline</code> ranges
from 278 to 1680, whilst <code>MalicAcid</code> ranges from 0.74 to
5.8. So first we need to normalise the data, so that they’re on a common scale.</p>
<div class="tab">
<button class="tablinksunnamed-chunk-39 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-39', 'unnamed-chunk-39');">
R
</button>
<button class="tablinksunnamed-chunk-39" onclick="javascript:openCode(event, 'option2unnamed-chunk-39', 'unnamed-chunk-39');">
Python
</button>
</div>
<div id="option1unnamed-chunk-39" class="tabcontentunnamed-chunk-39">
<div class="sourceCode" id="cb38"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb38-1" data-line-number="1">wineType &lt;-<span class="st"> </span>xTrain<span class="op">$</span>WineType <span class="co"># save for comparison</span></a>
<a class="sourceLine" id="cb38-2" data-line-number="2">xTrain &lt;-<span class="st"> </span><span class="kw">scale</span>(xTrain[<span class="op">-</span><span class="dv">1</span>], <span class="dt">center=</span><span class="ot">TRUE</span>, <span class="dt">scale=</span><span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb38-3" data-line-number="3"><span class="kw">print</span>(<span class="kw">head</span>(xTrain))</a></code></pre></div>
<pre><code>       Alcohol   MalicAcid        Ash AlcalinityAsh  Magnesium TotalPhenols
[1,] 1.5143408 -0.56066822  0.2313998    -1.1663032 1.90852151    0.8067217
[2,] 0.2455968 -0.49800856 -0.8256672    -2.4838405 0.01809398    0.5670481
[3,] 0.1963252  0.02117152  1.1062139    -0.2679823 0.08810981    0.8067217
[4,] 1.6867914 -0.34583508  0.4865539    -0.8069748 0.92829983    2.4844372
[5,] 0.2948684  0.22705328  1.8352256     0.4506745 1.27837900    0.8067217
[6,] 1.4773871 -0.51591132  0.3043010    -1.2860793 0.85828399    1.5576991
     Flavanoids NonflavanoidPhenols Proanthocyanins ColorIntensity        Hue
[1,]  1.0319081          -0.6577078       1.2214385      0.2510088  0.3611585
[2,]  0.7315653          -0.8184106      -0.5431887     -0.2924962  0.4049085
[3,]  1.2121137          -0.4970050       2.1299594      0.2682629  0.3174085
[4,]  1.4623994          -0.9791134       1.0292513      1.1827317 -0.4263410
[5,]  0.6614853           0.2261576       0.4002753     -0.3183774  0.3611585
[6,]  1.3622851          -0.1755994       0.6623487      0.7298108  0.4049085
     OD280_OD315     Proline
[1,]   1.8427215  1.01015939
[2,]   1.1103172  0.96252635
[3,]   0.7863692  1.39122370
[4,]   1.1807407  2.32800680
[5,]   0.4483365 -0.03776747
[6,]   0.3356589  2.23274072</code></pre>
</div>
<div id="option2unnamed-chunk-39" class="tabcontentunnamed-chunk-39">
<div class="sourceCode" id="cb40"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb40-1" data-line-number="1"><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> scale</a>
<a class="sourceLine" id="cb40-2" data-line-number="2">wineType <span class="op">=</span> xTrain[<span class="st">&#39;WineType&#39;</span>] <span class="co"># save for comparison</span></a>
<a class="sourceLine" id="cb40-3" data-line-number="3">xTrain <span class="op">=</span> scale(xTrain.drop(labels<span class="op">=</span><span class="st">&#39;WineType&#39;</span>, axis<span class="op">=</span><span class="dv">1</span>), </a>
<a class="sourceLine" id="cb40-4" data-line-number="4">               with_mean<span class="op">=</span><span class="va">True</span>, with_std<span class="op">=</span><span class="va">True</span>)</a>
<a class="sourceLine" id="cb40-5" data-line-number="5"><span class="bu">print</span>(xTrain)</a></code></pre></div>
<pre><code>[[ 1.51861254 -0.5622498   0.23205254 ...  0.36217728  1.84791957
   1.01300893]
 [ 0.24628963 -0.49941338 -0.82799632 ...  0.40605066  1.1134493
   0.96524152]
 [ 0.19687903  0.02123125  1.10933436 ...  0.31830389  0.78858745
   1.39514818]
 ...
 [ 0.33275817  1.74474449 -0.38935541 ... -1.61212515 -1.48544548
   0.28057537]
 [ 0.20923168  0.22769377  0.01273209 ... -1.56825176 -1.40069891
   0.29649784]
 [ 1.39508604  1.58316512  1.36520822 ... -1.52437837 -1.42894777
  -0.59516041]]</code></pre>
</div>
<script> javascript:hide('option2unnamed-chunk-39') </script>
<div class="panel panel-default">
<div class="panel-heading">
Task
</div>
<div class="panel-body">
<ul>
<li><p>Perform <span class="math inline">\(k\)</span>-means clustering by allowing <span class="math inline">\(k\)</span> to vary from 1 to 10 .</p></li>
<li>Plot the intra and intercluster sum-of-squares as a function of <span class="math inline">\(k\)</span>
and deduce the “true” number of underlying clusters.
</div>
</div></li>
</ul>
<button id="displayTextunnamed-chunk-41" onclick="javascript:toggle('unnamed-chunk-41');">
Show Solution
</button>
<div id="toggleTextunnamed-chunk-41" style="display: none">
<div class="panel panel-default">
<div class="panel-heading panel-heading1">
Solution
</div>
<div class="panel-body">
<div class="tab">
<button class="tablinksunnamed-chunk-41 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-41', 'unnamed-chunk-41');">
R
</button>
<button class="tablinksunnamed-chunk-41" onclick="javascript:openCode(event, 'option2unnamed-chunk-41', 'unnamed-chunk-41');">
Python
</button>
</div>
<div id="option1unnamed-chunk-41" class="tabcontentunnamed-chunk-41">
<div class="sourceCode" id="cb42"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb42-1" data-line-number="1"><span class="co"># Initialise some variables</span></a>
<a class="sourceLine" id="cb42-2" data-line-number="2">kRange &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from=</span><span class="dv">1</span>, <span class="dt">to=</span><span class="dv">10</span>, <span class="dt">by=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb42-3" data-line-number="3">intra &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">length</span>(kRange)) <span class="co"># intracluster sum-of-squares</span></a>
<a class="sourceLine" id="cb42-4" data-line-number="4">inter &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">length</span>(kRange)) <span class="co"># intercluster sum-of-squares</span></a>
<a class="sourceLine" id="cb42-5" data-line-number="5"></a>
<a class="sourceLine" id="cb42-6" data-line-number="6"><span class="co"># Loop across desired range of ks</span></a>
<a class="sourceLine" id="cb42-7" data-line-number="7"><span class="cf">for</span> (k <span class="cf">in</span> kRange) {</a>
<a class="sourceLine" id="cb42-8" data-line-number="8">    mdl &lt;-<span class="st"> </span><span class="kw">kmeans</span>(<span class="dt">x=</span>xTrain , <span class="dt">centers=</span>k)</a>
<a class="sourceLine" id="cb42-9" data-line-number="9">    intra[k] &lt;-<span class="st"> </span>mdl<span class="op">$</span>tot.withinss</a>
<a class="sourceLine" id="cb42-10" data-line-number="10">    inter[k] &lt;-<span class="st"> </span>mdl<span class="op">$</span>betweenss </a>
<a class="sourceLine" id="cb42-11" data-line-number="11">}</a>
<a class="sourceLine" id="cb42-12" data-line-number="12"></a>
<a class="sourceLine" id="cb42-13" data-line-number="13"><span class="co"># Plot inter/intercluster sum-of-squares as a function of $k$</span></a>
<a class="sourceLine" id="cb42-14" data-line-number="14">yMin &lt;-<span class="st"> </span><span class="kw">min</span>(<span class="kw">c</span>(intra , inter)) </a>
<a class="sourceLine" id="cb42-15" data-line-number="15">yMax &lt;-<span class="st"> </span><span class="kw">max</span>(<span class="kw">c</span>(intra , inter))</a>
<a class="sourceLine" id="cb42-16" data-line-number="16"><span class="kw">plot</span>(kRange, inter, <span class="dt">type=</span><span class="st">&quot;o&quot;</span>, <span class="dt">pch=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">lty=</span><span class="dv">1</span>, </a>
<a class="sourceLine" id="cb42-17" data-line-number="17">     <span class="dt">ylim=</span><span class="kw">c</span>(yMin, yMax), <span class="dt">xlab=</span><span class="st">&quot;k&quot;</span>, <span class="dt">ylab=</span><span class="st">&#39;Sum-of-squares&#39;</span>)</a>
<a class="sourceLine" id="cb42-18" data-line-number="18"><span class="kw">points</span>(kRange, intra, <span class="dt">type=</span><span class="st">&quot;o&quot;</span>, <span class="dt">pch=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>)</a>
<a class="sourceLine" id="cb42-19" data-line-number="19"><span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="kw">c</span>(<span class="st">&quot;inter-cluster&quot;</span>, <span class="st">&quot;intra-cluster&quot;</span>), </a>
<a class="sourceLine" id="cb42-20" data-line-number="20">       <span class="dt">bty=</span><span class="st">&quot;n&quot;</span>, <span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;blue&quot;</span>, <span class="st">&quot;red&quot;</span>), <span class="dt">pch=</span><span class="dv">1</span>, <span class="dt">lwd=</span><span class="dv">3</span>, <span class="dt">lty=</span><span class="dv">1</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-90-1.png" style="display: block; margin: auto;" /></p>
<p>The “correct” number of clusters is approximately 3.
This matches our expectation.</p>
</div>
<div id="option2unnamed-chunk-41" class="tabcontentunnamed-chunk-41">
<div class="sourceCode" id="cb43"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb43-1" data-line-number="1"><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> scale</a>
<a class="sourceLine" id="cb43-2" data-line-number="2"></a>
<a class="sourceLine" id="cb43-3" data-line-number="3"><span class="co"># Initialise some variables</span></a>
<a class="sourceLine" id="cb43-4" data-line-number="4">kRange <span class="op">=</span> <span class="bu">range</span>(<span class="dv">1</span>, <span class="dv">11</span>)</a>
<a class="sourceLine" id="cb43-5" data-line-number="5">intra <span class="op">=</span> np.empty(<span class="bu">len</span>(kRange)) <span class="co"># intracluster sum-of-squares</span></a>
<a class="sourceLine" id="cb43-6" data-line-number="6">inter <span class="op">=</span> np.empty(<span class="bu">len</span>(kRange)) <span class="co"># intercluster sum-of-squares</span></a>
<a class="sourceLine" id="cb43-7" data-line-number="7"></a>
<a class="sourceLine" id="cb43-8" data-line-number="8"><span class="co"># Loop across desired range of ks</span></a>
<a class="sourceLine" id="cb43-9" data-line-number="9"><span class="cf">for</span> k <span class="kw">in</span> kRange:</a>
<a class="sourceLine" id="cb43-10" data-line-number="10">    mdl <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k)</a>
<a class="sourceLine" id="cb43-11" data-line-number="11">    mdl.fit(X<span class="op">=</span>xTrain)</a>
<a class="sourceLine" id="cb43-12" data-line-number="12">    intra[k<span class="dv">-1</span>] <span class="op">=</span> mdl.inertia_ </a>
<a class="sourceLine" id="cb43-13" data-line-number="13">    inter[k<span class="dv">-1</span>] <span class="op">=</span> np.<span class="bu">sum</span>(scale(xTrain, with_std<span class="op">=</span><span class="va">False</span>)<span class="op">**</span><span class="dv">2</span>) <span class="op">-</span> mdl.inertia_</a>
<a class="sourceLine" id="cb43-14" data-line-number="14"></a>
<a class="sourceLine" id="cb43-15" data-line-number="15"><span class="co"># Plot inter/intercluster sum-of-squares as a function of $k$</span></a></code></pre></div>
<div class="sourceCode" id="cb44"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb44-1" data-line-number="1">plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">5</span>))</a>
<a class="sourceLine" id="cb44-2" data-line-number="2">plt.plot(kRange, inter, <span class="st">&#39;bo-&#39;</span>, label<span class="op">=</span><span class="st">&#39;inter-cluster&#39;</span>)</a>
<a class="sourceLine" id="cb44-3" data-line-number="3">plt.plot(kRange, intra, <span class="st">&#39;ro-&#39;</span>, label<span class="op">=</span><span class="st">&#39;intra-cluster&#39;</span>)</a>
<a class="sourceLine" id="cb44-4" data-line-number="4">plt.legend(loc<span class="op">=</span><span class="st">&#39;upper right&#39;</span>)</a>
<a class="sourceLine" id="cb44-5" data-line-number="5">plt.xlabel(<span class="st">&#39;k&#39;</span>)</a>
<a class="sourceLine" id="cb44-6" data-line-number="6">plt.ylabel(<span class="st">&#39;Sum-of-squares&#39;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-91-1.png" width="480" style="display: block; margin: auto;" /></p>
<p>The “correct” number of clusters is approximately 3.
This matches our expectation.</p>
</div>
<script> javascript:hide('option2unnamed-chunk-41') </script>
</div>
</div>
</div>
<div class="panel panel-default">
<div class="panel-heading">
Task
</div>
<div class="panel-body">
<ul>
<li><p>Perform silhouette analysis on the clusters obtained with <span class="math inline">\(k\)</span>-means for <span class="math inline">\(k\)</span> = 2 to 5.</p></li>
<li>What’s the suggested number of clusters?
</div>
</div></li>
</ul>
<button id="displayTextunnamed-chunk-43" onclick="javascript:toggle('unnamed-chunk-43');">
Show Solution
</button>
<div id="toggleTextunnamed-chunk-43" style="display: none">
<div class="panel panel-default">
<div class="panel-heading panel-heading1">
Solution
</div>
<div class="panel-body">
<div class="tab">
<button class="tablinksunnamed-chunk-43 active" onclick="javascript:openCode(event, 'option1unnamed-chunk-43', 'unnamed-chunk-43');">
R
</button>
<button class="tablinksunnamed-chunk-43" onclick="javascript:openCode(event, 'option2unnamed-chunk-43', 'unnamed-chunk-43');">
Python
</button>
</div>
<div id="option1unnamed-chunk-43" class="tabcontentunnamed-chunk-43">
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb45-1" data-line-number="1"><span class="kw">library</span>(cluster) <span class="co"># for silhouette function</span></a>
<a class="sourceLine" id="cb45-2" data-line-number="2"></a>
<a class="sourceLine" id="cb45-3" data-line-number="3"><span class="co"># Initialise some variables</span></a>
<a class="sourceLine" id="cb45-4" data-line-number="4">kRange &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dt">from=</span><span class="dv">2</span>, <span class="dt">to=</span><span class="dv">5</span>, <span class="dt">by=</span><span class="dv">1</span>)</a>
<a class="sourceLine" id="cb45-5" data-line-number="5">avgWidth &lt;-<span class="st"> </span><span class="kw">rep</span>(<span class="ot">NA</span>, <span class="kw">length</span>(kRange))</a>
<a class="sourceLine" id="cb45-6" data-line-number="6"></a>
<a class="sourceLine" id="cb45-7" data-line-number="7"><span class="co"># Loop across desired range of ks</span></a>
<a class="sourceLine" id="cb45-8" data-line-number="8"><span class="cf">for</span> (k <span class="cf">in</span> kRange) {</a>
<a class="sourceLine" id="cb45-9" data-line-number="9">    mdl &lt;-<span class="st"> </span><span class="kw">kmeans</span>(<span class="dt">x=</span>xTrain , <span class="dt">centers=</span>k)</a>
<a class="sourceLine" id="cb45-10" data-line-number="10">    silh &lt;-<span class="st"> </span><span class="kw">silhouette</span>(mdl<span class="op">$</span>cluster, <span class="kw">dist</span>(xTrain))</a>
<a class="sourceLine" id="cb45-11" data-line-number="11">    <span class="kw">plot</span>(silh, <span class="dt">main=</span><span class="kw">paste0</span>(<span class="st">&#39;k=&#39;</span>, k))</a>
<a class="sourceLine" id="cb45-12" data-line-number="12">    avgWidth[k<span class="dv">-1</span>] &lt;-<span class="st"> </span><span class="kw">mean</span>(silh[, <span class="dv">3</span>])</a>
<a class="sourceLine" id="cb45-13" data-line-number="13">}</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-92-1.png" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-92-2.png" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-92-3.png" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-92-4.png" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb46-1" data-line-number="1"><span class="co"># Plot average width as a function of k </span></a>
<a class="sourceLine" id="cb46-2" data-line-number="2"><span class="kw">plot</span>(kRange, avgWidth, <span class="dt">type=</span><span class="st">&quot;o&quot;</span>, <span class="dt">pch=</span><span class="dv">1</span>, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>, </a>
<a class="sourceLine" id="cb46-3" data-line-number="3">     <span class="dt">lty=</span><span class="dv">1</span>, <span class="dt">xlab=</span><span class="st">&quot;k&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Average silhouette width&quot;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-92-5.png" style="display: block; margin: auto;" /></p>
<p>The “correct” number of clusters is approximately 3.
This matches our expectation. However, note that the average
silhouette width is quite low, suggesting that some wines
are ambiguously assigned to a cluster, and that in general the clusters are not
very homogenous.</p>
</div>
<div id="option2unnamed-chunk-43" class="tabcontentunnamed-chunk-43">
<div class="sourceCode" id="cb47"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb47-1" data-line-number="1"><span class="co"># Unfortunately in scikit-learn there is not a readily available function</span></a>
<a class="sourceLine" id="cb47-2" data-line-number="2"><span class="co"># to plot silhouettes, so we will have to write one ourselves</span></a>
<a class="sourceLine" id="cb47-3" data-line-number="3"><span class="co"># Adapted from scikit-learn:</span></a>
<a class="sourceLine" id="cb47-4" data-line-number="4"><span class="im">from</span> sklearn.metrics <span class="im">import</span> silhouette_samples, silhouette_score</a>
<a class="sourceLine" id="cb47-5" data-line-number="5"><span class="im">import</span> numpy <span class="im">as</span> np</a>
<a class="sourceLine" id="cb47-6" data-line-number="6"></a>
<a class="sourceLine" id="cb47-7" data-line-number="7"><span class="co">#===================================================================#</span></a>
<a class="sourceLine" id="cb47-8" data-line-number="8"><span class="kw">def</span> plot_silhouette(mdl, xTrain):</a>
<a class="sourceLine" id="cb47-9" data-line-number="9">    <span class="co">&quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb47-10" data-line-number="10"><span class="co">    Plots a silhouette plot for a k-means object mdl</span></a>
<a class="sourceLine" id="cb47-11" data-line-number="11"><span class="co">    It also requires the training data xTrain</span></a>
<a class="sourceLine" id="cb47-12" data-line-number="12"><span class="co">    &quot;&quot;&quot;</span></a>
<a class="sourceLine" id="cb47-13" data-line-number="13">    <span class="co"># Compute the silhouette scores for all samples</span></a>
<a class="sourceLine" id="cb47-14" data-line-number="14">    clustLabels <span class="op">=</span> mdl.labels_</a>
<a class="sourceLine" id="cb47-15" data-line-number="15">    silhScores <span class="op">=</span> silhouette_samples(xTrain, clustLabels)</a>
<a class="sourceLine" id="cb47-16" data-line-number="16">    </a>
<a class="sourceLine" id="cb47-17" data-line-number="17">    <span class="co"># Loop across all clusters</span></a>
<a class="sourceLine" id="cb47-18" data-line-number="18">    hFig <span class="op">=</span> plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>,<span class="dv">6</span>))</a>
<a class="sourceLine" id="cb47-19" data-line-number="19">    yMin <span class="op">=</span> <span class="dv">10</span></a>
<a class="sourceLine" id="cb47-20" data-line-number="20">    <span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(mdl.n_clusters):</a>
<a class="sourceLine" id="cb47-21" data-line-number="21">        <span class="co"># Aggregate scores for that cluster and sort them</span></a>
<a class="sourceLine" id="cb47-22" data-line-number="22">        thisSilhScores <span class="op">=</span> silhScores[clustLabels <span class="op">==</span> i]</a>
<a class="sourceLine" id="cb47-23" data-line-number="23">        thisSilhScores.sort()</a>
<a class="sourceLine" id="cb47-24" data-line-number="24">        </a>
<a class="sourceLine" id="cb47-25" data-line-number="25">        <span class="co"># Set plot limits and plot</span></a>
<a class="sourceLine" id="cb47-26" data-line-number="26">        yMax <span class="op">=</span> yMin <span class="op">+</span> <span class="bu">len</span>(thisSilhScores)</a>
<a class="sourceLine" id="cb47-27" data-line-number="27">        plt.fill_betweenx(np.arange(yMin, yMax), <span class="dv">0</span>, thisSilhScores, </a>
<a class="sourceLine" id="cb47-28" data-line-number="28">                          facecolor<span class="op">=</span><span class="st">&#39;grey&#39;</span>, edgecolor<span class="op">=</span><span class="st">&#39;black&#39;</span>, alpha<span class="op">=</span><span class="fl">0.7</span>)</a>
<a class="sourceLine" id="cb47-29" data-line-number="29">        plt.xlabel(<span class="st">&#39;Silhouette width $s_i$&#39;</span>)</a>
<a class="sourceLine" id="cb47-30" data-line-number="30">        plt.title(<span class="st">&#39;k=</span><span class="sc">{}</span><span class="st">, n=</span><span class="sc">{}</span><span class="ch">\n</span><span class="st"> Average silhouette width: </span><span class="sc">{:.2f}</span><span class="st">&#39;</span>\</a>
<a class="sourceLine" id="cb47-31" data-line-number="31">                  .<span class="bu">format</span>(mdl.n_clusters, xTrain.shape[<span class="dv">0</span>], np.mean(silhScores)))</a>
<a class="sourceLine" id="cb47-32" data-line-number="32"></a>
<a class="sourceLine" id="cb47-33" data-line-number="33">        <span class="co"># Leave space before plotting next cluster</span></a>
<a class="sourceLine" id="cb47-34" data-line-number="34">        yMin <span class="op">=</span> yMax <span class="op">+</span> <span class="dv">10</span></a>
<a class="sourceLine" id="cb47-35" data-line-number="35">    </a>
<a class="sourceLine" id="cb47-36" data-line-number="36">    <span class="co"># Show plot</span></a>
<a class="sourceLine" id="cb47-37" data-line-number="37">    plt.show()</a>
<a class="sourceLine" id="cb47-38" data-line-number="38">    </a>
<a class="sourceLine" id="cb47-39" data-line-number="39">    <span class="cf">return</span> hFig</a>
<a class="sourceLine" id="cb47-40" data-line-number="40">    </a>
<a class="sourceLine" id="cb47-41" data-line-number="41"><span class="co">#===================================================================#</span></a>
<a class="sourceLine" id="cb47-42" data-line-number="42">    </a>
<a class="sourceLine" id="cb47-43" data-line-number="43"><span class="co"># Initialise some variables</span></a>
<a class="sourceLine" id="cb47-44" data-line-number="44">kRange <span class="op">=</span> <span class="bu">range</span>(<span class="dv">2</span>, <span class="dv">6</span>)</a>
<a class="sourceLine" id="cb47-45" data-line-number="45">avgWidth <span class="op">=</span> np.empty(<span class="bu">len</span>(kRange))</a>
<a class="sourceLine" id="cb47-46" data-line-number="46"></a>
<a class="sourceLine" id="cb47-47" data-line-number="47"><span class="co"># Loop across desired range of ks</span></a>
<a class="sourceLine" id="cb47-48" data-line-number="48"><span class="cf">for</span> k <span class="kw">in</span> kRange:</a>
<a class="sourceLine" id="cb47-49" data-line-number="49">    mdl <span class="op">=</span> KMeans(n_clusters<span class="op">=</span>k).fit(X<span class="op">=</span>xTrain)</a>
<a class="sourceLine" id="cb47-50" data-line-number="50">    avgWidth[k<span class="dv">-2</span>] <span class="op">=</span> silhouette_score(xTrain, mdl.labels_)</a>
<a class="sourceLine" id="cb47-51" data-line-number="51">    plot_silhouette(mdl, xTrain)</a>
<a class="sourceLine" id="cb47-52" data-line-number="52"></a>
<a class="sourceLine" id="cb47-53" data-line-number="53"><span class="co"># Plot average width as a function of k</span></a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-93-1.png" width="576" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-93-2.png" width="576" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-93-3.png" width="576" style="display: block; margin: auto;" /><img src="_main_files/figure-html/unnamed-chunk-93-4.png" width="576" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb48"><pre class="sourceCode python"><code class="sourceCode python"><a class="sourceLine" id="cb48-1" data-line-number="1">plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>,<span class="dv">5</span>))</a>
<a class="sourceLine" id="cb48-2" data-line-number="2">plt.plot(kRange, avgWidth, <span class="st">&#39;bo-&#39;</span>)</a>
<a class="sourceLine" id="cb48-3" data-line-number="3">plt.xlabel(<span class="st">&#39;k&#39;</span>)</a>
<a class="sourceLine" id="cb48-4" data-line-number="4">plt.ylabel(<span class="st">&#39;Average silhouette width&#39;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-93-5.png" width="480" style="display: block; margin: auto;" /></p>
<p>The “correct” number of clusters is approximately 3.
This matches our expectation. However, note that the average
silhouette width is quite low, suggesting that some wines
are ambiguously assigned to a cluster, and that in general the clusters are not
very homogenous.</p>
</div>
<script> javascript:hide('option2unnamed-chunk-43') </script>
</div>
</div>
</div>

</div>
</div>
</div>
<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>Nowadays microarrays have been largely replaced by sequencing technologies. However, the problem remains exactly the same<a href="clustering.html#fnref1" class="footnote-back">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="dimensionality-reduction.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
